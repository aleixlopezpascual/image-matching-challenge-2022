{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T18:07:47.120937Z",
     "iopub.status.busy": "2022-04-17T18:07:47.120151Z",
     "iopub.status.idle": "2022-04-17T18:07:47.162885Z",
     "shell.execute_reply": "2022-04-17T18:07:47.162108Z",
     "shell.execute_reply.started": "2022-04-17T18:07:47.120898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n",
      "Collecting torch>=1.8.1\n",
      "  Using cached torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from kornia==0.6.4) (21.3)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging->kornia==0.6.4) (3.0.9)\n",
      "Installing collected packages: typing-extensions, torch, kornia\n",
      "Successfully installed kornia-0.6.4 torch-1.11.0 typing-extensions-4.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Processing ./input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "Requirement already satisfied: kornia in /usr/local/lib/python3.8/site-packages (from kornia-moons==0.1.9) (0.6.4)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/site-packages (from kornia-moons==0.1.9) (1.11.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from kornia->kornia-moons==0.1.9) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torch->kornia-moons==0.1.9) (4.2.0)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->kornia-moons==0.1.9) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib->kornia-moons==0.1.9) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->kornia-moons==0.1.9) (1.16.0)\n",
      "Installing collected packages: pillow, numpy, kiwisolver, fonttools, cycler, opencv-python, matplotlib, kornia-moons\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 kiwisolver-1.4.2 kornia-moons-0.1.9 matplotlib-3.5.2 numpy-1.22.4 opencv-python-4.5.5.64 pillow-9.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Processing ./input/loftrutils/einops-0.4.1-py3-none-any.whl\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ./input/kornia-loftr/kornia-0.6.4-py2.py3-none-any.whl\n",
    "!pip install ./input/kornia-loftr/kornia_moons-0.1.9-py3-none-any.whl\n",
    "!pip install ./input/loftrutils/einops-0.4.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loguru\n",
      "  Using cached loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: loguru\n",
      "Successfully installed loguru-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning==1.6.3\n",
      "  Using cached pytorch_lightning-1.6.3-py3-none-any.whl (584 kB)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Using cached torchmetrics-0.9.0-py3-none-any.whl (418 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/site-packages (from pytorch-lightning==1.6.3) (4.2.0)\n",
      "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.8/site-packages (from pytorch-lightning==1.6.3) (1.11.0)\n",
      "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/site-packages (from pytorch-lightning==1.6.3) (1.22.4)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/site-packages (from pytorch-lightning==1.6.3) (5.4.1)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Using cached fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Using cached tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/site-packages (from pytorch-lightning==1.6.3) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.3) (2.27.1)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning==1.6.3) (3.0.9)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.46.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.3) (57.5.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-4.21.1-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.3) (0.37.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.3) (4.7.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.3) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.3) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.3) (2022.5.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.3) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.3) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.3) (2.0.12)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "Installing collected packages: zipp, pyasn1-modules, oauthlib, multidict, frozenlist, cachetools, yarl, requests-oauthlib, importlib-metadata, google-auth, attrs, async-timeout, aiosignal, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, fsspec, aiohttp, absl-py, tqdm, torchmetrics, tensorboard, pyDeprecate, pytorch-lightning\n",
      "Successfully installed absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 attrs-21.4.0 cachetools-5.2.0 frozenlist-1.3.0 fsspec-2022.5.0 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.46.3 importlib-metadata-4.11.4 markdown-3.3.7 multidict-6.0.2 oauthlib-3.2.0 protobuf-4.21.1 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pytorch-lightning-1.6.3 requests-oauthlib-1.3.1 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torchmetrics-0.9.0 tqdm-4.64.0 werkzeug-2.1.2 yarl-1.7.2 zipp-3.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting protobuf==3.20\n",
      "  Using cached protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.1\n",
      "    Uninstalling protobuf-4.21.1:\n",
      "      Successfully uninstalled protobuf-4.21.1\n",
      "Successfully installed protobuf-3.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting yacs\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/site-packages (from yacs) (5.4.1)\n",
      "Installing collected packages: yacs\n",
      "Successfully installed yacs-0.1.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/site-packages (from h5py) (1.22.4)\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Using cached opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "Collecting scikit-image>=0.16.1\n",
      "  Using cached scikit_image-0.19.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/site-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/site-packages (from albumentations) (1.22.4)\n",
      "Collecting qudida>=0.0.4\n",
      "  Using cached qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "Collecting scikit-learn>=0.19.1\n",
      "  Using cached scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (4.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Using cached tifffile-2022.5.4-py3-none-any.whl (195 kB)\n",
      "Collecting imageio>=2.4.1\n",
      "  Using cached imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
      "Collecting networkx>=2.2\n",
      "  Using cached networkx-2.8.2-py3-none-any.whl (2.0 MB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Using cached PyWavelets-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Installing collected packages: threadpoolctl, scipy, tifffile, scikit-learn, PyWavelets, opencv-python-headless, networkx, imageio, scikit-image, qudida, albumentations\n",
      "Successfully installed PyWavelets-1.3.0 albumentations-1.1.0 imageio-2.19.3 networkx-2.8.2 opencv-python-headless-4.5.5.64 qudida-0.0.4 scikit-image-0.19.2 scikit-learn-1.1.1 scipy-1.8.1 threadpoolctl-3.1.0 tifffile-2022.5.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/site-packages (from pandas) (1.22.4)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.4.2 pytz-2022.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/site-packages (from ipywidgets) (8.3.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/site-packages (from ipywidgets) (6.13.0)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Using cached widgetsnbextension-3.6.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Using cached jupyterlab_widgets-1.1.0-py3-none-any.whl (245 kB)\n",
      "Collecting ipython-genutils~=0.2.0\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Using cached nbformat-5.4.0-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/site-packages (from ipywidgets) (5.2.1.post0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.29)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.12.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (57.5.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.10.0)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /usr/local/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (23.0.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Collecting jsonschema>=2.6\n",
      "  Using cached jsonschema-4.6.0-py3-none-any.whl (80 kB)\n",
      "Collecting fastjsonschema\n",
      "  Using cached fastjsonschema-2.15.3-py3-none-any.whl (22 kB)\n",
      "Collecting importlib-resources>=1.4.0\n",
      "  Using cached importlib_resources-5.7.1-py3-none-any.whl (28 kB)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Using cached pyrsistent-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (3.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Collecting notebook>=4.4.1\n",
      "  Using cached notebook-6.4.11-py3-none-any.whl (9.9 MB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "Collecting nbconvert>=5\n",
      "  Using cached nbconvert-6.5.0-py3-none-any.whl (561 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Using cached terminado-0.15.0-py3-none-any.whl (16 kB)\n",
      "Collecting argon2-cffi\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-5.0.0-py3-none-any.whl (160 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Using cached nbclient-0.6.4-py3-none-any.whl (71 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting tinycss2\n",
      "  Using cached tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting traitlets>=4.3.1\n",
      "  Using cached traitlets-5.2.2.post1-py3-none-any.whl (106 kB)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Collecting cffi>=1.0.1\n",
      "  Using cached cffi-1.15.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: executing in /usr/local/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /usr/local/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Installing collected packages: traitlets, pyrsistent, importlib-resources, pycparser, jsonschema, fastjsonschema, webencodings, soupsieve, nbformat, MarkupSafe, cffi, tinycss2, pandocfilters, nbclient, mistune, jupyterlab-pygments, jinja2, defusedxml, bleach, beautifulsoup4, argon2-cffi-bindings, terminado, Send2Trash, prometheus-client, nbconvert, ipython-genutils, argon2-cffi, notebook, widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.2.1.post0\n",
      "    Uninstalling traitlets-5.2.1.post0:\n",
      "      Successfully uninstalled traitlets-5.2.1.post0\n",
      "Successfully installed MarkupSafe-2.1.1 Send2Trash-1.8.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 beautifulsoup4-4.11.1 bleach-5.0.0 cffi-1.15.0 defusedxml-0.7.1 fastjsonschema-2.15.3 importlib-resources-5.7.1 ipython-genutils-0.2.0 ipywidgets-7.7.0 jinja2-3.1.2 jsonschema-4.6.0 jupyterlab-pygments-0.2.2 jupyterlab-widgets-1.1.0 mistune-0.8.4 nbclient-0.6.4 nbconvert-6.5.0 nbformat-5.4.0 notebook-6.4.11 pandocfilters-1.5.0 prometheus-client-0.14.1 pycparser-2.21 pyrsistent-0.18.1 soupsieve-2.3.2.post1 terminado-0.15.0 tinycss2-1.1.1 traitlets-5.2.2.post1 webencodings-0.5.1 widgetsnbextension-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# SageMaker Image: Base Python 2.0\n",
    "SAGEMAKER_IMAGE = True\n",
    "if SAGEMAKER_IMAGE:\n",
    "    !pip install pytorch-lightning==1.6.3\n",
    "    !pip install protobuf==3.20\n",
    "    !pip install yacs\n",
    "    !pip install joblib\n",
    "    !pip install h5py\n",
    "    !pip install albumentations\n",
    "    !pip install pandas\n",
    "    !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from loguru import logger\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"./input/loftrutils/LoFTR-master/LoFTR-master/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.loftr import LoFTR\n",
    "from src.loftr.utils.supervision import (\n",
    "    compute_supervision_coarse,\n",
    "    compute_supervision_fine,\n",
    ")\n",
    "from src.losses.loftr_loss import LoFTRLoss\n",
    "from src.optimizers import build_optimizer, build_scheduler\n",
    "from src.utils.comm import all_gather, gather\n",
    "from src.utils.metrics import (\n",
    "    aggregate_metrics,\n",
    "    compute_pose_errors,\n",
    "    compute_symmetrical_epipolar_errors,\n",
    ")\n",
    "from src.utils.misc import flattenList, lower_config\n",
    "from src.utils.plotting import make_matching_figures\n",
    "from src.utils.profiler import PassThroughProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PL_LoFTR(pl.LightningModule):\n",
    "    def __init__(self, config, pretrained_ckpt=None, profiler=None, dump_dir=None):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "            - use the new version of PL logging API.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Misc\n",
    "        self.config = config  # full config\n",
    "        _config = lower_config(self.config)\n",
    "        self.loftr_cfg = lower_config(_config[\"loftr\"])\n",
    "        self.profiler = profiler or PassThroughProfiler()\n",
    "        self.n_vals_plot = (\n",
    "            1  # max(config.TRAINER.N_VAL_PAIRS_TO_PLOT // config.TRAINER.WORLD_SIZE, 1)\n",
    "        )\n",
    "\n",
    "        # Matcher: LoFTR\n",
    "        self.matcher = LoFTR(config=_config[\"loftr\"])\n",
    "        self.loss = LoFTRLoss(_config)\n",
    "\n",
    "        # Pretrained weights\n",
    "        if pretrained_ckpt:\n",
    "            state_dict = torch.load(pretrained_ckpt, map_location=\"cuda\")[\"state_dict\"]\n",
    "            self.matcher.load_state_dict(state_dict, strict=True)\n",
    "            logger.info(f\"Load '{pretrained_ckpt}' as pretrained checkpoint\")\n",
    "\n",
    "        # Testing\n",
    "        self.dump_dir = dump_dir\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # FIXME: The scheduler did not work properly when `--resume_from_checkpoint`\n",
    "        optimizer = build_optimizer(self, self.config)\n",
    "        scheduler = build_scheduler(self.config, optimizer)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def optimizer_step(\n",
    "        self,\n",
    "        epoch,\n",
    "        batch_idx,\n",
    "        optimizer,\n",
    "        optimizer_idx,\n",
    "        optimizer_closure,\n",
    "        on_tpu,\n",
    "        using_native_amp,\n",
    "        using_lbfgs,\n",
    "    ):\n",
    "        # learning rate warm up\n",
    "        warmup_step = self.config.TRAINER.WARMUP_STEP\n",
    "        if self.trainer.global_step < warmup_step:\n",
    "            if self.config.TRAINER.WARMUP_TYPE == \"linear\":\n",
    "                base_lr = self.config.TRAINER.WARMUP_RATIO * self.config.TRAINER.TRUE_LR\n",
    "                lr = base_lr + (\n",
    "                    self.trainer.global_step / self.config.TRAINER.WARMUP_STEP\n",
    "                ) * abs(self.config.TRAINER.TRUE_LR - base_lr)\n",
    "                for pg in optimizer.param_groups:\n",
    "                    pg[\"lr\"] = lr\n",
    "            elif self.config.TRAINER.WARMUP_TYPE == \"constant\":\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Unknown lr warm-up strategy: {self.config.TRAINER.WARMUP_TYPE}\"\n",
    "                )\n",
    "\n",
    "        # update params\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    def _trainval_inference(self, batch):\n",
    "        with self.profiler.profile(\"Compute coarse supervision\"):\n",
    "            compute_supervision_coarse(batch, self.config)\n",
    "\n",
    "        with self.profiler.profile(\"LoFTR\"):\n",
    "            self.matcher(batch)\n",
    "\n",
    "        with self.profiler.profile(\"Compute fine supervision\"):\n",
    "            compute_supervision_fine(batch, self.config)\n",
    "\n",
    "        with self.profiler.profile(\"Compute losses\"):\n",
    "            self.loss(batch)\n",
    "\n",
    "    def _compute_metrics(self, batch):\n",
    "        with self.profiler.profile(\"Copmute metrics\"):\n",
    "            compute_symmetrical_epipolar_errors(\n",
    "                batch\n",
    "            )  # compute epi_errs for each match\n",
    "            compute_pose_errors(\n",
    "                batch, self.config\n",
    "            )  # compute R_errs, t_errs, pose_errs for each pair\n",
    "\n",
    "            rel_pair_names = list(zip(*batch[\"pair_names\"]))\n",
    "            bs = batch[\"image0\"].size(0)\n",
    "            metrics = {\n",
    "                # to filter duplicate pairs caused by DistributedSampler\n",
    "                \"identifiers\": [\"#\".join(rel_pair_names[b]) for b in range(bs)],\n",
    "                \"epi_errs\": [\n",
    "                    batch[\"epi_errs\"][batch[\"m_bids\"] == b].cpu().numpy()\n",
    "                    for b in range(bs)\n",
    "                ],\n",
    "                \"R_errs\": batch[\"R_errs\"],\n",
    "                \"t_errs\": batch[\"t_errs\"],\n",
    "                \"inliers\": batch[\"inliers\"],\n",
    "            }\n",
    "            ret_dict = {\"metrics\": metrics}\n",
    "        return ret_dict, rel_pair_names\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self._trainval_inference(batch)\n",
    "\n",
    "        # logging\n",
    "        if (\n",
    "            self.trainer.global_rank == 0\n",
    "            and self.global_step % self.trainer.log_every_n_steps == 0\n",
    "        ):\n",
    "            # scalars\n",
    "            for k, v in batch[\"loss_scalars\"].items():\n",
    "                self.logger.experiment.add_scalar(f\"train/{k}\", v, self.global_step)\n",
    "\n",
    "            # net-params\n",
    "            if self.config.LOFTR.MATCH_COARSE.MATCH_TYPE == \"sinkhorn\":\n",
    "                self.logger.experiment.add_scalar(\n",
    "                    f\"skh_bin_score\",\n",
    "                    self.matcher.coarse_matching.bin_score.clone().detach().cpu().data,\n",
    "                    self.global_step,\n",
    "                )\n",
    "\n",
    "            # figures\n",
    "            if self.config.TRAINER.ENABLE_PLOTTING:\n",
    "                compute_symmetrical_epipolar_errors(\n",
    "                    batch\n",
    "                )  # compute epi_errs for each match\n",
    "                figures = make_matching_figures(\n",
    "                    batch, self.config, self.config.TRAINER.PLOT_MODE\n",
    "                )\n",
    "                for k, v in figures.items():\n",
    "                    self.logger.experiment.add_figure(\n",
    "                        f\"train_match/{k}\", v, self.global_step\n",
    "                    )\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return {\"loss\": batch[\"loss\"]}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        if self.trainer.global_rank == 0:\n",
    "            self.logger.experiment.add_scalar(\n",
    "                \"train/avg_loss_on_epoch\", avg_loss, global_step=self.current_epoch\n",
    "            )\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._trainval_inference(batch)\n",
    "\n",
    "        ret_dict, _ = self._compute_metrics(batch)\n",
    "\n",
    "        val_plot_interval = max(self.trainer.num_val_batches[0] // self.n_vals_plot, 1)\n",
    "        figures = {self.config.TRAINER.PLOT_MODE: []}\n",
    "        if batch_idx % val_plot_interval == 0:\n",
    "            figures = make_matching_figures(\n",
    "                batch, self.config, mode=self.config.TRAINER.PLOT_MODE\n",
    "            )\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return {\n",
    "            **ret_dict,\n",
    "            \"loss_scalars\": batch[\"loss_scalars\"],\n",
    "            \"figures\": figures,\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # handle multiple validation sets\n",
    "        multi_outputs = (\n",
    "            [outputs] if not isinstance(outputs[0], (list, tuple)) else outputs\n",
    "        )\n",
    "        multi_val_metrics = defaultdict(list)\n",
    "\n",
    "        for valset_idx, outputs in enumerate(multi_outputs):\n",
    "            # since pl performs sanity_check at the very begining of the training\n",
    "            cur_epoch = self.trainer.current_epoch\n",
    "            if not self.trainer.resume_from_checkpoint:\n",
    "                cur_epoch = -1\n",
    "\n",
    "            # 1. loss_scalars: dict of list, on cpu\n",
    "            _loss_scalars = [o[\"loss_scalars\"] for o in outputs]\n",
    "            loss_scalars = {\n",
    "                k: flattenList(all_gather([_ls[k] for _ls in _loss_scalars]))\n",
    "                for k in _loss_scalars[0]\n",
    "            }\n",
    "\n",
    "            # 2. val metrics: dict of list, numpy\n",
    "            _metrics = [o[\"metrics\"] for o in outputs]\n",
    "            metrics = {\n",
    "                k: flattenList(all_gather(flattenList([_me[k] for _me in _metrics])))\n",
    "                for k in _metrics[0]\n",
    "            }\n",
    "            # NOTE: all ranks need to `aggregate_merics`, but only log at rank-0\n",
    "            val_metrics_4tb = aggregate_metrics(\n",
    "                metrics, self.config.TRAINER.EPI_ERR_THR\n",
    "            )\n",
    "            for thr in [5, 10, 20]:\n",
    "                multi_val_metrics[f\"auc@{thr}\"].append(val_metrics_4tb[f\"auc@{thr}\"])\n",
    "\n",
    "            # 3. figures\n",
    "            _figures = [o[\"figures\"] for o in outputs]\n",
    "            figures = {\n",
    "                k: flattenList(gather(flattenList([_me[k] for _me in _figures])))\n",
    "                for k in _figures[0]\n",
    "            }\n",
    "\n",
    "            # tensorboard records only on rank 0\n",
    "            if self.trainer.global_rank == 0:\n",
    "                for k, v in loss_scalars.items():\n",
    "                    mean_v = torch.stack(v).mean()\n",
    "                    self.logger.experiment.add_scalar(\n",
    "                        f\"val_{valset_idx}/avg_{k}\", mean_v, global_step=cur_epoch\n",
    "                    )\n",
    "\n",
    "                for k, v in val_metrics_4tb.items():\n",
    "                    self.logger.experiment.add_scalar(\n",
    "                        f\"metrics_{valset_idx}/{k}\", v, global_step=cur_epoch\n",
    "                    )\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            plt.close(\"all\")\n",
    "\n",
    "        for thr in [5, 10, 20]:\n",
    "            # log on all ranks for ModelCheckpoint callback to work properly\n",
    "            self.log(\n",
    "                f\"auc@{thr}\", torch.tensor(np.mean(multi_val_metrics[f\"auc@{thr}\"]))\n",
    "            )  # ckpt monitors on this\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        with self.profiler.profile(\"LoFTR\"):\n",
    "            self.matcher(batch)\n",
    "\n",
    "        ret_dict, rel_pair_names = self._compute_metrics(batch)\n",
    "\n",
    "        with self.profiler.profile(\"dump_results\"):\n",
    "            if self.dump_dir is not None:\n",
    "                # dump results for further analysis\n",
    "                keys_to_save = {\"mkpts0_f\", \"mkpts1_f\", \"mconf\", \"epi_errs\"}\n",
    "                pair_names = list(zip(*batch[\"pair_names\"]))\n",
    "                bs = batch[\"image0\"].shape[0]\n",
    "                dumps = []\n",
    "                for b_id in range(bs):\n",
    "                    item = {}\n",
    "                    mask = batch[\"m_bids\"] == b_id\n",
    "                    item[\"pair_names\"] = pair_names[b_id]\n",
    "                    item[\"identifier\"] = \"#\".join(rel_pair_names[b_id])\n",
    "                    for key in keys_to_save:\n",
    "                        item[key] = batch[key][mask].cpu().numpy()\n",
    "                    for key in [\"R_errs\", \"t_errs\", \"inliers\"]:\n",
    "                        item[key] = batch[key][b_id]\n",
    "                    dumps.append(item)\n",
    "                ret_dict[\"dumps\"] = dumps\n",
    "\n",
    "        return ret_dict\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        # metrics: dict of list, numpy\n",
    "        _metrics = [o[\"metrics\"] for o in outputs]\n",
    "        metrics = {\n",
    "            k: flattenList(gather(flattenList([_me[k] for _me in _metrics])))\n",
    "            for k in _metrics[0]\n",
    "        }\n",
    "\n",
    "        # [{key: [{...}, *#bs]}, *#batch]\n",
    "        if self.dump_dir is not None:\n",
    "            Path(self.dump_dir).mkdir(parents=True, exist_ok=True)\n",
    "            _dumps = flattenList([o[\"dumps\"] for o in outputs])  # [{...}, #bs*#batch]\n",
    "            dumps = flattenList(gather(_dumps))  # [{...}, #proc*#bs*#batch]\n",
    "            logger.info(\n",
    "                f\"Prediction and evaluation results will be saved to: {self.dump_dir}\"\n",
    "            )\n",
    "\n",
    "        if self.trainer.global_rank == 0:\n",
    "            print(self.profiler.summary())\n",
    "            val_metrics_4tb = aggregate_metrics(\n",
    "                metrics, self.config.TRAINER.EPI_ERR_THR\n",
    "            )\n",
    "            logger.info(\"\\n\" + pprint.pformat(val_metrics_4tb))\n",
    "            if self.dump_dir is not None:\n",
    "                np.save(Path(self.dump_dir) / \"LoFTR_pred_eval\", dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_megadepth_depth(path, pad_to=None):\n",
    "    \"\"\"\n",
    "    cv2.imread() method loads an image from the specified file.\n",
    "    If the image cannot be read (because of missing file, improper permissions, unsupported or invalid format) then this method returns an empty matrix.\n",
    "    \"\"\"\n",
    "    depth = cv2.imread(path, 0)\n",
    "    if pad_to is not None:\n",
    "        depth, _ = pad_bottom_right(depth, pad_to, ret_mask=False)\n",
    "    depth = torch.from_numpy(depth).float()  # (h, w)\n",
    "    gc.collect()\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from loguru import logger\n",
    "from src.utils.dataset import pad_bottom_right, read_megadepth_gray\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MegaDepthDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        npz_path,\n",
    "        mode=\"train\",\n",
    "        min_overlap_score=0.4,\n",
    "        img_resize=None,\n",
    "        df=None,\n",
    "        img_padding=False,\n",
    "        depth_padding=False,\n",
    "        augment_fn=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Manage one scene(npz_path) of MegaDepth dataset.\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): megadepth root directory that has `phoenix`.\n",
    "            npz_path (str): {scene_id}.npz path. This contains image pair information of a scene.\n",
    "            mode (str): options are ['train', 'val', 'test']\n",
    "            min_overlap_score (float): how much a pair should have in common. In range of [0, 1]. Set to 0 when testing.\n",
    "            img_resize (int, optional): the longer edge of resized images. None for no resize. 640 is recommended.\n",
    "                                        This is useful during training with batches and testing with memory intensive algorithms.\n",
    "            df (int, optional): image size division factor. NOTE: this will change the final image size after img_resize.\n",
    "            img_padding (bool): If set to 'True', zero-pad the image to squared size. This is useful during training.\n",
    "            depth_padding (bool): If set to 'True', zero-pad depthmap to (2000, 2000). This is useful during training.\n",
    "            augment_fn (callable, optional): augments images with pre-defined visual effects.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "\n",
    "        # prepare scene_info and pair_info\n",
    "        if mode == \"test\" and min_overlap_score != 0:\n",
    "            logger.warning(\n",
    "                \"You are using `min_overlap_score`!=0 in test mode. Set to 0.\"\n",
    "            )\n",
    "            min_overlap_score = 0\n",
    "\n",
    "        # parameters for image resizing, padding and depthmap padding\n",
    "        if mode == \"train\":\n",
    "            assert img_resize is not None and img_padding and depth_padding\n",
    "        self.img_resize = img_resize\n",
    "        self.df = df\n",
    "        self.img_padding = img_padding\n",
    "        self.depth_max_size = (\n",
    "            2000 if depth_padding else None\n",
    "        )  # the upperbound of depthmaps size in megadepth.\n",
    "\n",
    "        # for training LoFTR\n",
    "        self.augment_fn = augment_fn if mode == \"train\" else None\n",
    "        self.coarse_scale = getattr(kwargs, \"coarse_scale\", 0.125)\n",
    "        self.path1 = data[\"path1\"].values\n",
    "        self.path2 = data[\"path2\"].values\n",
    "        self.camerainst1 = data[\"camerainst1\"].values\n",
    "        self.camerainst2 = data[\"camerainst2\"].values\n",
    "        self.rot1 = data[\"rot1\"].values\n",
    "        self.rot2 = data[\"rot2\"].values\n",
    "        self.trans1 = data[\"trans1\"].values\n",
    "        self.trans2 = data[\"trans2\"].values\n",
    "        gc.collect()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read grayscale image and mask. (1, h, w) and (h, w)\n",
    "        img_name0 = self.path1[idx]\n",
    "        img_name1 = self.path2[idx]\n",
    "        if SAGEMAKER_IMAGE:\n",
    "            # img_name0, img_name1 come from the imc-gt/train.csv. The paths in the dataset\n",
    "            # are defined as ../input/image-matching-challenge-2022/train/british_museum/images/93658023_4980549800.jpg\n",
    "            # I must change it to ./input/...\n",
    "            img_name0 = img_name0.replace(\"..\", \".\")\n",
    "            img_name1 = img_name1.replace(\"..\", \".\")\n",
    "\n",
    "        # TODO: Support augmentation & handle seeds for each worker correctly.\n",
    "        image0, mask0, scale0 = read_megadepth_gray(\n",
    "            img_name0, self.img_resize, self.df, self.img_padding, None\n",
    "        )\n",
    "        # np.random.choice([self.augment_fn, None], p=[0.5, 0.5]))\n",
    "        image1, mask1, scale1 = read_megadepth_gray(\n",
    "            img_name1, self.img_resize, self.df, self.img_padding, None\n",
    "        )\n",
    "        # np.random.choice([self.augment_fn, None], p=[0.5, 0.5]))\n",
    "        depth_path0 = (\n",
    "            \"./input/depth-masks-imc2022/depth_maps/\"\n",
    "            + img_name0.split(\"/\")[-3]\n",
    "            + \"/\"\n",
    "            + img_name0.split(\"/\")[-1]\n",
    "        )\n",
    "        depth_path1 = (\n",
    "            \"./input/depth-masks-imc2022/depth_maps/\"\n",
    "            + img_name1.split(\"/\")[-3]\n",
    "            + \"/\"\n",
    "            + img_name1.split(\"/\")[-1]\n",
    "        )\n",
    "\n",
    "        # read depth. shape: (h, w)\n",
    "        if self.mode in [\"train\", \"val\"]:\n",
    "            depth0 = read_megadepth_depth(depth_path0, pad_to=self.depth_max_size)\n",
    "            depth1 = read_megadepth_depth(depth_path1, pad_to=self.depth_max_size)\n",
    "        else:\n",
    "            depth0 = depth1 = torch.tensor([])\n",
    "\n",
    "        # read intrinsics of original size\n",
    "        K_0 = torch.tensor(\n",
    "            np.asarray([float(x) for x in self.camerainst1[idx].split(\" \")]),\n",
    "            dtype=torch.float,\n",
    "        ).reshape(3, 3)\n",
    "        K_1 = torch.tensor(\n",
    "            np.asarray([float(x) for x in self.camerainst2[idx].split(\" \")]),\n",
    "            dtype=torch.float,\n",
    "        ).reshape(3, 3)\n",
    "\n",
    "        # read and compute relative poses\n",
    "        R0 = self.rot1[idx].replace(\"{\", \"\").replace(\"}\", \"\").replace(\"'\", \"\")\n",
    "        R0 = np.asarray([float(x) for x in R0.split(\" \")]).reshape(3, 3)\n",
    "        Tv0 = self.trans1[idx].replace(\"{\", \"\").replace(\"}\", \"\").replace(\"'\", \"\")\n",
    "        Tv0 = np.asarray([[float(x) for x in Tv0.split(\" \")]])\n",
    "        T0 = np.concatenate((R0, Tv0.T), axis=1)\n",
    "        T0 = np.concatenate((T0, np.asarray([[0, 0, 0, 1]])), axis=0)\n",
    "        del R0\n",
    "        del Tv0\n",
    "        R1 = self.rot2[idx].replace(\"{\", \"\").replace(\"}\", \"\").replace(\"'\", \"\")\n",
    "        R1 = np.asarray([float(x) for x in R1.split(\" \")]).reshape(3, 3)\n",
    "        Tv1 = self.trans2[idx].replace(\"{\", \"\").replace(\"}\", \"\").replace(\"'\", \"\")\n",
    "        Tv1 = np.asarray([[float(x) for x in Tv1.split(\" \")]])\n",
    "        T1 = np.concatenate((R1, Tv1.T), axis=1)\n",
    "        T1 = np.concatenate((T1, np.asarray([[0, 0, 0, 1]])), axis=0)\n",
    "        del R1\n",
    "        del Tv1\n",
    "        T_0to1 = torch.tensor(np.matmul(T1, np.linalg.inv(T0)), dtype=torch.float)[\n",
    "            :4, :4\n",
    "        ]  # (4, 4)\n",
    "        T_1to0 = T_0to1.inverse()\n",
    "\n",
    "        data = {\n",
    "            \"image0\": image0,  # (1, h, w)\n",
    "            \"depth0\": depth0,  # (h, w)\n",
    "            \"image1\": image1,\n",
    "            \"depth1\": depth1,\n",
    "            \"T_0to1\": T_0to1,  # (4, 4)\n",
    "            \"T_1to0\": T_1to0,\n",
    "            \"K0\": K_0,  # (3, 3)\n",
    "            \"K1\": K_1,\n",
    "            \"scale0\": scale0,  # [scale_w, scale_h]\n",
    "            \"scale1\": scale1,\n",
    "            \"dataset_name\": \"MegaDepth\",\n",
    "            \"scene_id\": idx,\n",
    "            \"pair_id\": idx,\n",
    "            \"pair_names\": (img_name0, img_name1),\n",
    "        }\n",
    "\n",
    "        # for LoFTR training\n",
    "        if mask0 is not None:  # img_padding is True\n",
    "            if self.coarse_scale:\n",
    "                [ts_mask_0, ts_mask_1] = F.interpolate(\n",
    "                    torch.stack([mask0, mask1], dim=0)[None].float(),\n",
    "                    scale_factor=self.coarse_scale,\n",
    "                    mode=\"nearest\",\n",
    "                    recompute_scale_factor=False,\n",
    "                )[0].bool()\n",
    "            data.update({\"mask0\": ts_mask_0, \"mask1\": ts_mask_1})\n",
    "        del image0\n",
    "        del image1\n",
    "        del depth0\n",
    "        del depth1\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T18:07:47.164761Z",
     "iopub.status.busy": "2022-04-17T18:07:47.164502Z",
     "iopub.status.idle": "2022-04-17T18:07:48.814359Z",
     "shell.execute_reply": "2022-04-17T18:07:48.813564Z",
     "shell.execute_reply.started": "2022-04-17T18:07:47.164728Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from collections import abc\n",
    "from os import path as osp\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from joblib import Parallel, delayed\n",
    "from loguru import logger\n",
    "from src.datasets.sampler import RandomConcatSampler\n",
    "from src.utils import comm\n",
    "from src.utils.augment import build_augmentor\n",
    "from src.utils.dataloader import get_local_split\n",
    "from src.utils.misc import tqdm_joblib\n",
    "from torch import distributed as dist\n",
    "from torch.utils.data import (\n",
    "    ConcatDataset,\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    DistributedSampler,\n",
    "    RandomSampler,\n",
    "    dataloader,\n",
    ")\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class MultiSceneDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    For distributed training, each training process is assgined\n",
    "    only a part of the training scenes to reduce memory overhead.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args, config, data):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. data config\n",
    "        # Train and Val should from the same data source\n",
    "        self.trainval_data_source = config.DATASET.TRAINVAL_DATA_SOURCE\n",
    "        self.test_data_source = config.DATASET.TEST_DATA_SOURCE\n",
    "        # training and validating\n",
    "        self.train_data = data\n",
    "        self.train_pose_root = config.DATASET.TRAIN_POSE_ROOT  # (optional)\n",
    "        self.train_npz_root = config.DATASET.TRAIN_NPZ_ROOT\n",
    "        self.train_list_path = config.DATASET.TRAIN_LIST_PATH\n",
    "        self.train_intrinsic_path = config.DATASET.TRAIN_INTRINSIC_PATH\n",
    "        self.val_data = data\n",
    "        self.val_pose_root = config.DATASET.VAL_POSE_ROOT  # (optional)\n",
    "        self.val_npz_root = config.DATASET.VAL_NPZ_ROOT\n",
    "        self.val_list_path = config.DATASET.VAL_LIST_PATH\n",
    "        self.val_intrinsic_path = config.DATASET.VAL_INTRINSIC_PATH\n",
    "        # testing\n",
    "        self.test_data = data\n",
    "        self.test_pose_root = config.DATASET.TEST_POSE_ROOT  # (optional)\n",
    "        self.test_npz_root = config.DATASET.TEST_NPZ_ROOT\n",
    "        self.test_list_path = config.DATASET.TEST_LIST_PATH\n",
    "        self.test_intrinsic_path = config.DATASET.TEST_INTRINSIC_PATH\n",
    "\n",
    "        # 2. dataset config\n",
    "        # general options\n",
    "        self.min_overlap_score_test = (\n",
    "            config.DATASET.MIN_OVERLAP_SCORE_TEST\n",
    "        )  # 0.4, omit data with overlap_score < min_overlap_score\n",
    "        self.min_overlap_score_train = config.DATASET.MIN_OVERLAP_SCORE_TRAIN\n",
    "        self.augment_fn = build_augmentor(\n",
    "            config.DATASET.AUGMENTATION_TYPE\n",
    "        )  # None, options: [None, 'dark', 'mobile']\n",
    "\n",
    "        # MegaDepth options\n",
    "        self.mgdpt_img_resize = config.DATASET.MGDPT_IMG_RESIZE  # 840\n",
    "        self.mgdpt_img_pad = config.DATASET.MGDPT_IMG_PAD  # True\n",
    "        self.mgdpt_depth_pad = config.DATASET.MGDPT_DEPTH_PAD  # True\n",
    "        self.mgdpt_df = config.DATASET.MGDPT_DF  # 8\n",
    "        self.coarse_scale = 1 / config.LOFTR.RESOLUTION[0]  # 0.125. for training loftr.\n",
    "\n",
    "        # 3.loader parameters\n",
    "        self.train_loader_params = {\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"num_workers\": args.num_workers,\n",
    "            \"pin_memory\": getattr(args, \"pin_memory\", True),\n",
    "        }\n",
    "        self.val_loader_params = {\n",
    "            \"batch_size\": 1,\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": args.num_workers,\n",
    "            \"pin_memory\": getattr(args, \"pin_memory\", True),\n",
    "        }\n",
    "        self.test_loader_params = {\n",
    "            \"batch_size\": 1,\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": args.num_workers,\n",
    "            \"pin_memory\": True,\n",
    "        }\n",
    "\n",
    "        # 4. sampler\n",
    "        self.data_sampler = config.TRAINER.DATA_SAMPLER\n",
    "        self.n_samples_per_subset = config.TRAINER.N_SAMPLES_PER_SUBSET\n",
    "        self.subset_replacement = config.TRAINER.SB_SUBSET_SAMPLE_REPLACEMENT\n",
    "        self.shuffle = config.TRAINER.SB_SUBSET_SHUFFLE\n",
    "        self.repeat = config.TRAINER.SB_REPEAT\n",
    "\n",
    "        # (optional) RandomSampler for debugging\n",
    "\n",
    "        # misc configurations\n",
    "        self.parallel_load_data = getattr(args, \"parallel_load_data\", False)\n",
    "        self.seed = config.TRAINER.SEED  # 66\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Setup train / val / test dataset. This method will be called by PL automatically.\n",
    "        Args:\n",
    "            stage (str): 'fit' in training phase, and 'test' in testing phase.\n",
    "        \"\"\"\n",
    "\n",
    "        assert stage in [\"fit\", \"test\"], \"stage must be either fit or test\"\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = self._setup_dataset(\n",
    "                self.train_data,\n",
    "                self.train_npz_root,\n",
    "                self.train_list_path,\n",
    "                self.train_intrinsic_path,\n",
    "                mode=\"train\",\n",
    "                min_overlap_score=self.min_overlap_score_train,\n",
    "                pose_dir=self.train_pose_root,\n",
    "            )\n",
    "            # setup multiple (optional) validation subsets\n",
    "\n",
    "            self.val_dataset = self._setup_dataset(\n",
    "                self.val_data,\n",
    "                self.val_npz_root,\n",
    "                self.val_list_path,\n",
    "                self.val_intrinsic_path,\n",
    "                mode=\"val\",\n",
    "                min_overlap_score=self.min_overlap_score_test,\n",
    "                pose_dir=self.val_pose_root,\n",
    "            )\n",
    "\n",
    "        else:  # stage == 'test\n",
    "            self.test_dataset = self._setup_dataset(\n",
    "                self.test_data,\n",
    "                self.test_npz_root,\n",
    "                self.test_list_path,\n",
    "                self.test_intrinsic_path,\n",
    "                mode=\"test\",\n",
    "                min_overlap_score=self.min_overlap_score_test,\n",
    "                pose_dir=self.test_pose_root,\n",
    "            )\n",
    "\n",
    "    def _setup_dataset(\n",
    "        self,\n",
    "        data,\n",
    "        split_npz_root,\n",
    "        scene_list_path,\n",
    "        intri_path,\n",
    "        mode=\"train\",\n",
    "        min_overlap_score=0.0,\n",
    "        pose_dir=None,\n",
    "    ):\n",
    "        \"\"\"Setup train / val / test set\"\"\"\n",
    "        local_npz_names = \"\"\n",
    "        dataset_builder = self._build_concat_dataset\n",
    "        return dataset_builder(\n",
    "            data,\n",
    "            local_npz_names,\n",
    "            split_npz_root,\n",
    "            intri_path,\n",
    "            mode=mode,\n",
    "            min_overlap_score=min_overlap_score,\n",
    "            pose_dir=pose_dir,\n",
    "        )\n",
    "\n",
    "    def _build_concat_dataset(\n",
    "        self,\n",
    "        data,\n",
    "        npz_names,\n",
    "        npz_dir,\n",
    "        intrinsic_path,\n",
    "        mode,\n",
    "        min_overlap_score=0.0,\n",
    "        pose_dir=None,\n",
    "    ):\n",
    "        datasets = []\n",
    "        augment_fn = self.augment_fn if mode == \"train\" else None\n",
    "        data_source = (\n",
    "            self.trainval_data_source\n",
    "            if mode in [\"train\", \"val\"]\n",
    "            else self.test_data_source\n",
    "        )\n",
    "        npz_path = \"\"\n",
    "\n",
    "        datasets.append(\n",
    "            MegaDepthDataset(\n",
    "                data,\n",
    "                npz_path,\n",
    "                mode=mode,\n",
    "                min_overlap_score=min_overlap_score,\n",
    "                img_resize=self.mgdpt_img_resize,\n",
    "                df=self.mgdpt_df,\n",
    "                img_padding=self.mgdpt_img_pad,\n",
    "                depth_padding=self.mgdpt_depth_pad,\n",
    "                augment_fn=augment_fn,\n",
    "                coarse_scale=self.coarse_scale,\n",
    "            )\n",
    "        )\n",
    "        concatdataset = ConcatDataset(datasets)\n",
    "        return concatdataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Build training dataloader for ScanNet / MegaDepth.\"\"\"\n",
    "        #         assert self.data_sampler in ['scene_balance']\n",
    "        #         #logger.info(f'[rank:{self.rank}/{self.world_size}]: Train Sampler and DataLoader re-init (should not re-init between epochs!).')\n",
    "        #         if self.data_sampler == 'scene_balance':\n",
    "        #             sampler = RandomConcatSampler(self.train_dataset,\n",
    "        #                                           self.n_samples_per_subset,\n",
    "        #                                           self.subset_replacement,\n",
    "        #                                           self.shuffle, self.repeat, self.seed)\n",
    "        #         else:\n",
    "        #             sampler = None\n",
    "        dataloader = DataLoader(\n",
    "            self.train_dataset, drop_last=True, **self.train_loader_params\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Build validation dataloader for ScanNet / MegaDepth.\"\"\"\n",
    "        # logger.info(f'[rank:{self.rank}/{self.world_size}]: Val Sampler and DataLoader re-init.')\n",
    "\n",
    "        print(len(self.val_dataset))\n",
    "        print(self.val_dataset)\n",
    "        dataloader = DataLoader(\n",
    "            self.val_dataset, drop_last=True, **self.val_loader_params\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def test_dataloader(self, *args, **kwargs):\n",
    "        # logger.info(f'[rank:{self.rank}/{self.world_size}]: Test Sampler and DataLoader re-init.')\n",
    "        sampler = DistributedSampler(self.test_dataset, shuffle=False)\n",
    "        return DataLoader(self.test_dataset, sampler=sampler, **self.test_loader_params)\n",
    "\n",
    "\n",
    "def _build_dataset(dataset: Dataset, *args, **kwargs):\n",
    "    return dataset(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T18:07:48.816121Z",
     "iopub.status.busy": "2022-04-17T18:07:48.815847Z",
     "iopub.status.idle": "2022-04-17T18:07:48.849851Z",
     "shell.execute_reply": "2022-04-17T18:07:48.849185Z",
     "shell.execute_reply.started": "2022-04-17T18:07:48.816083Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import pprint\n",
    "from distutils.util import strtobool\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from loguru import logger as loguru_logger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "from src.config.default import get_cfg_defaults\n",
    "from src.utils.misc import get_rank_zero_only_logger, setup_gpus\n",
    "from src.utils.profiler import build_profiler\n",
    "\n",
    "loguru_logger = get_rank_zero_only_logger(loguru_logger)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # init a costum parser which will be added into pl.Trainer parser\n",
    "    # check documentation: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument(\"data_cfg_path\", type=str, help=\"data config path\")\n",
    "    parser.add_argument(\"main_cfg_path\", type=str, help=\"main config path\")\n",
    "    parser.add_argument(\"--exp_name\", type=str, default=\"default_exp_name\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=4, help=\"batch_size per gpu\")\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=4)\n",
    "    parser.add_argument(\n",
    "        \"--pin_memory\",\n",
    "        type=lambda x: bool(strtobool(x)),\n",
    "        nargs=\"?\",\n",
    "        default=True,\n",
    "        help=\"whether loading data to pinned memory or not\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ckpt_path\",\n",
    "        type=str,\n",
    "        default=\"./input/kornia-loftr/outdoor_ds.ckpt\",\n",
    "        help=\"pretrained checkpoint path, helpful for using a pre-trained coarse-only LoFTR\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--disable_ckpt\",\n",
    "        action=\"store_true\",\n",
    "        help=\"disable checkpoint saving (useful for debugging).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--profiler_name\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"options: [inference, pytorch], or leave it unset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--parallel_load_data\",\n",
    "        action=\"store_true\",\n",
    "        help=\"load datasets in with multiple processes.\",\n",
    "    )\n",
    "\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # -- RUN CFG\n",
    "    n_nodes = 0\n",
    "    n_gpus_per_node = 1\n",
    "    torch_num_workers = 0\n",
    "    batch_size = 1\n",
    "    max_epochs = 30\n",
    "    exp_name = \"final_training\"\n",
    "    # exp_name=f\"outdoor-ds-640-bs-gpus-{n_gpus_per_node}-n-nodes-{n_nodes}-batch-size-{batch_size}\"\n",
    "\n",
    "    return parser.parse_args(\n",
    "        f\"./input/loftrutils/LoFTR-master/LoFTR-master/configs/data/megadepth_trainval_640.py \"\n",
    "        f\"./input/loftrutils/LoFTR-master/LoFTR-master/configs/loftr/outdoor/loftr_ds_dense.py \"\n",
    "        f\"--exp_name {exp_name} \"\n",
    "        f\"--gpus {n_gpus_per_node} \"\n",
    "        f\"--num_nodes {n_nodes} \"\n",
    "        f\"--accelerator gpu \"\n",
    "        f\"--batch_size {batch_size} \"\n",
    "        f\"--check_val_every_n_epoch 1 \"\n",
    "        f\"--log_every_n_steps 1 \"\n",
    "        f\"--flush_logs_every_n_steps 1 \"\n",
    "        f\"--limit_val_batches 1 \"\n",
    "        f\"--num_sanity_val_steps 10 \"\n",
    "        f\"--benchmark True \"\n",
    "        f\"--max_epochs {max_epochs} \"\n",
    "        # f\"--strategy dp \"\n",
    "        f\"--num_workers {torch_num_workers}\".split()\n",
    "    )\n",
    "\n",
    "\n",
    "def train():\n",
    "    # parse arguments\n",
    "    args = parse_args()\n",
    "    rank_zero_only(pprint.pprint)(vars(args))\n",
    "\n",
    "    # init default-cfg and merge it with the main- and data-cfg\n",
    "    config = get_cfg_defaults()\n",
    "    config.merge_from_file(args.main_cfg_path)\n",
    "    config.merge_from_file(args.data_cfg_path)\n",
    "    pl.seed_everything(config.TRAINER.SEED)  # reproducibility\n",
    "    # TODO: Use different seeds for each dataloader workers\n",
    "    # This is needed for data augmentation\n",
    "\n",
    "    # scale lr and warmup-step automatically\n",
    "    args.gpus = _n_gpus = setup_gpus(args.gpus)\n",
    "    config.TRAINER.WORLD_SIZE = _n_gpus * args.num_nodes\n",
    "    config.TRAINER.TRUE_BATCH_SIZE = config.TRAINER.WORLD_SIZE * args.batch_size\n",
    "    _scaling = 1  # config.TRAINER.TRUE_BATCH_SIZE / config.TRAINER.CANONICAL_BS\n",
    "    config.TRAINER.SCALING = _scaling\n",
    "    config.TRAINER.TRUE_LR = 0.00001 * _scaling\n",
    "    config.TRAINER.WARMUP_STEP = math.floor(config.TRAINER.WARMUP_STEP / _scaling)\n",
    "\n",
    "    # lightning module\n",
    "    profiler = build_profiler(args.profiler_name)\n",
    "    model = PL_LoFTR(config, pretrained_ckpt=args.ckpt_path, profiler=profiler)\n",
    "    loguru_logger.info(f\"LoFTR LightningModule initialized!\")\n",
    "\n",
    "    # lightning data\n",
    "    data = pd.read_csv(\"./input/imc-gt/train.csv\")\n",
    "    # TODO: only using 100 first samples! I should use all of them\n",
    "    # data[:100]\n",
    "    data_module = MultiSceneDataModule(args, config, data[:500])\n",
    "    gc.collect()\n",
    "    loguru_logger.info(f\"LoFTR DataModule initialized!\")\n",
    "\n",
    "    # TensorBoard Logger\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir=\"logs/tb_logs\", name=args.exp_name, default_hp_metric=False\n",
    "    )\n",
    "    ckpt_dir = Path(logger.log_dir) / \"checkpoints\"\n",
    "\n",
    "    # Callbacks\n",
    "    # TODO: update ModelCheckpoint to monitor multiple metrics\n",
    "    ckpt_callback = ModelCheckpoint(\n",
    "        monitor=\"auc@10\",\n",
    "        verbose=True,\n",
    "        save_top_k=5,\n",
    "        mode=\"max\",\n",
    "        save_last=True,\n",
    "        dirpath=str(ckpt_dir),\n",
    "        filename=\"{epoch}-{auc@5:.3f}-{auc@10:.3f}-{auc@20:.3f}\",\n",
    "    )\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "    callbacks = [lr_monitor]\n",
    "    if not args.disable_ckpt:\n",
    "        callbacks.append(ckpt_callback)\n",
    "\n",
    "    # Lightning Trainer\n",
    "    trainer = pl.Trainer.from_argparse_args(\n",
    "        args,\n",
    "        #         plugins=DDPPlugin(find_unused_parameters=False,\n",
    "        #                           num_nodes=args.num_nodes,\n",
    "        #                           sync_batchnorm=config.TRAINER.WORLD_SIZE > 0),\n",
    "        gradient_clip_val=config.TRAINER.GRADIENT_CLIPPING,\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "        # sync_batchnorm=config.TRAINER.WORLD_SIZE > 0,\n",
    "        replace_sampler_ddp=False,  # use custom sampler\n",
    "        # avoid repeated samples!\n",
    "        weights_summary=\"full\",\n",
    "        profiler=profiler,\n",
    "    )\n",
    "    loguru_logger.info(f\"Trainer initialized!\")\n",
    "    loguru_logger.info(f\"Start training!\")\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T18:07:48.851428Z",
     "iopub.status.busy": "2022-04-17T18:07:48.85116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accelerator': 'gpu',\n",
      " 'accumulate_grad_batches': None,\n",
      " 'amp_backend': 'native',\n",
      " 'amp_level': None,\n",
      " 'auto_lr_find': False,\n",
      " 'auto_scale_batch_size': False,\n",
      " 'auto_select_gpus': False,\n",
      " 'batch_size': 1,\n",
      " 'benchmark': True,\n",
      " 'check_val_every_n_epoch': 1,\n",
      " 'checkpoint_callback': None,\n",
      " 'ckpt_path': './input/kornia-loftr/outdoor_ds.ckpt',\n",
      " 'data_cfg_path': './input/loftrutils/LoFTR-master/LoFTR-master/configs/data/megadepth_trainval_640.py',\n",
      " 'default_root_dir': None,\n",
      " 'detect_anomaly': False,\n",
      " 'deterministic': False,\n",
      " 'devices': None,\n",
      " 'disable_ckpt': False,\n",
      " 'enable_checkpointing': True,\n",
      " 'enable_model_summary': True,\n",
      " 'enable_progress_bar': True,\n",
      " 'exp_name': 'final_training',\n",
      " 'fast_dev_run': False,\n",
      " 'flush_logs_every_n_steps': 1,\n",
      " 'gpus': 1,\n",
      " 'gradient_clip_algorithm': None,\n",
      " 'gradient_clip_val': None,\n",
      " 'ipus': None,\n",
      " 'limit_predict_batches': None,\n",
      " 'limit_test_batches': None,\n",
      " 'limit_train_batches': None,\n",
      " 'limit_val_batches': 1,\n",
      " 'log_every_n_steps': 1,\n",
      " 'log_gpu_memory': None,\n",
      " 'logger': True,\n",
      " 'main_cfg_path': './input/loftrutils/LoFTR-master/LoFTR-master/configs/loftr/outdoor/loftr_ds_dense.py',\n",
      " 'max_epochs': 30,\n",
      " 'max_steps': -1,\n",
      " 'max_time': None,\n",
      " 'min_epochs': None,\n",
      " 'min_steps': None,\n",
      " 'move_metrics_to_cpu': False,\n",
      " 'multiple_trainloader_mode': 'max_size_cycle',\n",
      " 'num_nodes': 0,\n",
      " 'num_processes': None,\n",
      " 'num_sanity_val_steps': 10,\n",
      " 'num_workers': 0,\n",
      " 'overfit_batches': 0.0,\n",
      " 'parallel_load_data': False,\n",
      " 'pin_memory': True,\n",
      " 'plugins': None,\n",
      " 'precision': 32,\n",
      " 'prepare_data_per_node': None,\n",
      " 'process_position': 0,\n",
      " 'profiler': None,\n",
      " 'profiler_name': None,\n",
      " 'progress_bar_refresh_rate': None,\n",
      " 'reload_dataloaders_every_n_epochs': 0,\n",
      " 'replace_sampler_ddp': True,\n",
      " 'resume_from_checkpoint': None,\n",
      " 'stochastic_weight_avg': False,\n",
      " 'strategy': None,\n",
      " 'sync_batchnorm': False,\n",
      " 'terminate_on_nan': None,\n",
      " 'tpu_cores': None,\n",
      " 'track_grad_norm': -1,\n",
      " 'val_check_interval': None,\n",
      " 'weights_save_path': None,\n",
      " 'weights_summary': 'top'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 11:25:21.407 | INFO     | __main__:__init__:25 - Load './input/kornia-loftr/outdoor_ds.ckpt' as pretrained checkpoint\n",
      "2022-06-02 11:25:21.409 | INFO     | __main__:train:119 - LoFTR LightningModule initialized!\n",
      "2022-06-02 11:25:32.279 | INFO     | __main__:train:127 - LoFTR DataModule initialized!\n",
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:191: LightningDeprecationWarning: Setting `Trainer(weights_summary=full)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.model_summary.ModelSummary` with `max_depth` directly to the Trainer's `callbacks` argument instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:61: LightningDeprecationWarning: Setting `Trainer(flush_logs_every_n_steps=1)` is deprecated in v1.5 and will be removed in v1.7. Please configure flushing in the logger instead.\n",
      "  rank_zero_deprecation(\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "2022-06-02 11:25:32.300 | INFO     | __main__:train:166 - Trainer initialized!\n",
      "2022-06-02 11:25:32.300 | INFO     | __main__:train:167 - Start training!\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "    | Name                                    | Type                    | Params\n",
      "--------------------------------------------------------------------------------------\n",
      "0   | matcher                                 | LoFTR                   | 11.6 M\n",
      "1   | matcher.backbone                        | ResNetFPN_8_2           | 5.9 M \n",
      "2   | matcher.backbone.conv1                  | Conv2d                  | 6.3 K \n",
      "3   | matcher.backbone.bn1                    | BatchNorm2d             | 256   \n",
      "4   | matcher.backbone.relu                   | ReLU                    | 0     \n",
      "5   | matcher.backbone.layer1                 | Sequential              | 590 K \n",
      "6   | matcher.backbone.layer1.0               | BasicBlock              | 295 K \n",
      "7   | matcher.backbone.layer1.0.conv1         | Conv2d                  | 147 K \n",
      "8   | matcher.backbone.layer1.0.conv2         | Conv2d                  | 147 K \n",
      "9   | matcher.backbone.layer1.0.bn1           | BatchNorm2d             | 256   \n",
      "10  | matcher.backbone.layer1.0.bn2           | BatchNorm2d             | 256   \n",
      "11  | matcher.backbone.layer1.0.relu          | ReLU                    | 0     \n",
      "12  | matcher.backbone.layer1.1               | BasicBlock              | 295 K \n",
      "13  | matcher.backbone.layer1.1.conv1         | Conv2d                  | 147 K \n",
      "14  | matcher.backbone.layer1.1.conv2         | Conv2d                  | 147 K \n",
      "15  | matcher.backbone.layer1.1.bn1           | BatchNorm2d             | 256   \n",
      "16  | matcher.backbone.layer1.1.bn2           | BatchNorm2d             | 256   \n",
      "17  | matcher.backbone.layer1.1.relu          | ReLU                    | 0     \n",
      "18  | matcher.backbone.layer2                 | Sequential              | 1.3 M \n",
      "19  | matcher.backbone.layer2.0               | BasicBlock              | 597 K \n",
      "20  | matcher.backbone.layer2.0.conv1         | Conv2d                  | 225 K \n",
      "21  | matcher.backbone.layer2.0.conv2         | Conv2d                  | 345 K \n",
      "22  | matcher.backbone.layer2.0.bn1           | BatchNorm2d             | 392   \n",
      "23  | matcher.backbone.layer2.0.bn2           | BatchNorm2d             | 392   \n",
      "24  | matcher.backbone.layer2.0.relu          | ReLU                    | 0     \n",
      "25  | matcher.backbone.layer2.0.downsample    | Sequential              | 25.5 K\n",
      "26  | matcher.backbone.layer2.0.downsample.0  | Conv2d                  | 25.1 K\n",
      "27  | matcher.backbone.layer2.0.downsample.1  | BatchNorm2d             | 392   \n",
      "28  | matcher.backbone.layer2.1               | BasicBlock              | 692 K \n",
      "29  | matcher.backbone.layer2.1.conv1         | Conv2d                  | 345 K \n",
      "30  | matcher.backbone.layer2.1.conv2         | Conv2d                  | 345 K \n",
      "31  | matcher.backbone.layer2.1.bn1           | BatchNorm2d             | 392   \n",
      "32  | matcher.backbone.layer2.1.bn2           | BatchNorm2d             | 392   \n",
      "33  | matcher.backbone.layer2.1.relu          | ReLU                    | 0     \n",
      "34  | matcher.backbone.layer3                 | Sequential              | 2.3 M \n",
      "35  | matcher.backbone.layer3.0               | BasicBlock              | 1.1 M \n",
      "36  | matcher.backbone.layer3.0.conv1         | Conv2d                  | 451 K \n",
      "37  | matcher.backbone.layer3.0.conv2         | Conv2d                  | 589 K \n",
      "38  | matcher.backbone.layer3.0.bn1           | BatchNorm2d             | 512   \n",
      "39  | matcher.backbone.layer3.0.bn2           | BatchNorm2d             | 512   \n",
      "40  | matcher.backbone.layer3.0.relu          | ReLU                    | 0     \n",
      "41  | matcher.backbone.layer3.0.downsample    | Sequential              | 50.7 K\n",
      "42  | matcher.backbone.layer3.0.downsample.0  | Conv2d                  | 50.2 K\n",
      "43  | matcher.backbone.layer3.0.downsample.1  | BatchNorm2d             | 512   \n",
      "44  | matcher.backbone.layer3.1               | BasicBlock              | 1.2 M \n",
      "45  | matcher.backbone.layer3.1.conv1         | Conv2d                  | 589 K \n",
      "46  | matcher.backbone.layer3.1.conv2         | Conv2d                  | 589 K \n",
      "47  | matcher.backbone.layer3.1.bn1           | BatchNorm2d             | 512   \n",
      "48  | matcher.backbone.layer3.1.bn2           | BatchNorm2d             | 512   \n",
      "49  | matcher.backbone.layer3.1.relu          | ReLU                    | 0     \n",
      "50  | matcher.backbone.layer3_outconv         | Conv2d                  | 65.5 K\n",
      "51  | matcher.backbone.layer2_outconv         | Conv2d                  | 50.2 K\n",
      "52  | matcher.backbone.layer2_outconv2        | Sequential              | 1.0 M \n",
      "53  | matcher.backbone.layer2_outconv2.0      | Conv2d                  | 589 K \n",
      "54  | matcher.backbone.layer2_outconv2.1      | BatchNorm2d             | 512   \n",
      "55  | matcher.backbone.layer2_outconv2.2      | LeakyReLU               | 0     \n",
      "56  | matcher.backbone.layer2_outconv2.3      | Conv2d                  | 451 K \n",
      "57  | matcher.backbone.layer1_outconv         | Conv2d                  | 25.1 K\n",
      "58  | matcher.backbone.layer1_outconv2        | Sequential              | 571 K \n",
      "59  | matcher.backbone.layer1_outconv2.0      | Conv2d                  | 345 K \n",
      "60  | matcher.backbone.layer1_outconv2.1      | BatchNorm2d             | 392   \n",
      "61  | matcher.backbone.layer1_outconv2.2      | LeakyReLU               | 0     \n",
      "62  | matcher.backbone.layer1_outconv2.3      | Conv2d                  | 225 K \n",
      "63  | matcher.pos_encoding                    | PositionEncodingSine    | 0     \n",
      "64  | matcher.loftr_coarse                    | LocalFeatureTransformer | 5.3 M \n",
      "65  | matcher.loftr_coarse.layers             | ModuleList              | 5.3 M \n",
      "66  | matcher.loftr_coarse.layers.0           | LoFTREncoderLayer       | 656 K \n",
      "67  | matcher.loftr_coarse.layers.0.q_proj    | Linear                  | 65.5 K\n",
      "68  | matcher.loftr_coarse.layers.0.k_proj    | Linear                  | 65.5 K\n",
      "69  | matcher.loftr_coarse.layers.0.v_proj    | Linear                  | 65.5 K\n",
      "70  | matcher.loftr_coarse.layers.0.attention | LinearAttention         | 0     \n",
      "71  | matcher.loftr_coarse.layers.0.merge     | Linear                  | 65.5 K\n",
      "72  | matcher.loftr_coarse.layers.0.mlp       | Sequential              | 393 K \n",
      "73  | matcher.loftr_coarse.layers.0.mlp.0     | Linear                  | 262 K \n",
      "74  | matcher.loftr_coarse.layers.0.mlp.1     | ReLU                    | 0     \n",
      "75  | matcher.loftr_coarse.layers.0.mlp.2     | Linear                  | 131 K \n",
      "76  | matcher.loftr_coarse.layers.0.norm1     | LayerNorm               | 512   \n",
      "77  | matcher.loftr_coarse.layers.0.norm2     | LayerNorm               | 512   \n",
      "78  | matcher.loftr_coarse.layers.1           | LoFTREncoderLayer       | 656 K \n",
      "79  | matcher.loftr_coarse.layers.1.q_proj    | Linear                  | 65.5 K\n",
      "80  | matcher.loftr_coarse.layers.1.k_proj    | Linear                  | 65.5 K\n",
      "81  | matcher.loftr_coarse.layers.1.v_proj    | Linear                  | 65.5 K\n",
      "82  | matcher.loftr_coarse.layers.1.attention | LinearAttention         | 0     \n",
      "83  | matcher.loftr_coarse.layers.1.merge     | Linear                  | 65.5 K\n",
      "84  | matcher.loftr_coarse.layers.1.mlp       | Sequential              | 393 K \n",
      "85  | matcher.loftr_coarse.layers.1.mlp.0     | Linear                  | 262 K \n",
      "86  | matcher.loftr_coarse.layers.1.mlp.1     | ReLU                    | 0     \n",
      "87  | matcher.loftr_coarse.layers.1.mlp.2     | Linear                  | 131 K \n",
      "88  | matcher.loftr_coarse.layers.1.norm1     | LayerNorm               | 512   \n",
      "89  | matcher.loftr_coarse.layers.1.norm2     | LayerNorm               | 512   \n",
      "90  | matcher.loftr_coarse.layers.2           | LoFTREncoderLayer       | 656 K \n",
      "91  | matcher.loftr_coarse.layers.2.q_proj    | Linear                  | 65.5 K\n",
      "92  | matcher.loftr_coarse.layers.2.k_proj    | Linear                  | 65.5 K\n",
      "93  | matcher.loftr_coarse.layers.2.v_proj    | Linear                  | 65.5 K\n",
      "94  | matcher.loftr_coarse.layers.2.attention | LinearAttention         | 0     \n",
      "95  | matcher.loftr_coarse.layers.2.merge     | Linear                  | 65.5 K\n",
      "96  | matcher.loftr_coarse.layers.2.mlp       | Sequential              | 393 K \n",
      "97  | matcher.loftr_coarse.layers.2.mlp.0     | Linear                  | 262 K \n",
      "98  | matcher.loftr_coarse.layers.2.mlp.1     | ReLU                    | 0     \n",
      "99  | matcher.loftr_coarse.layers.2.mlp.2     | Linear                  | 131 K \n",
      "100 | matcher.loftr_coarse.layers.2.norm1     | LayerNorm               | 512   \n",
      "101 | matcher.loftr_coarse.layers.2.norm2     | LayerNorm               | 512   \n",
      "102 | matcher.loftr_coarse.layers.3           | LoFTREncoderLayer       | 656 K \n",
      "103 | matcher.loftr_coarse.layers.3.q_proj    | Linear                  | 65.5 K\n",
      "104 | matcher.loftr_coarse.layers.3.k_proj    | Linear                  | 65.5 K\n",
      "105 | matcher.loftr_coarse.layers.3.v_proj    | Linear                  | 65.5 K\n",
      "106 | matcher.loftr_coarse.layers.3.attention | LinearAttention         | 0     \n",
      "107 | matcher.loftr_coarse.layers.3.merge     | Linear                  | 65.5 K\n",
      "108 | matcher.loftr_coarse.layers.3.mlp       | Sequential              | 393 K \n",
      "109 | matcher.loftr_coarse.layers.3.mlp.0     | Linear                  | 262 K \n",
      "110 | matcher.loftr_coarse.layers.3.mlp.1     | ReLU                    | 0     \n",
      "111 | matcher.loftr_coarse.layers.3.mlp.2     | Linear                  | 131 K \n",
      "112 | matcher.loftr_coarse.layers.3.norm1     | LayerNorm               | 512   \n",
      "113 | matcher.loftr_coarse.layers.3.norm2     | LayerNorm               | 512   \n",
      "114 | matcher.loftr_coarse.layers.4           | LoFTREncoderLayer       | 656 K \n",
      "115 | matcher.loftr_coarse.layers.4.q_proj    | Linear                  | 65.5 K\n",
      "116 | matcher.loftr_coarse.layers.4.k_proj    | Linear                  | 65.5 K\n",
      "117 | matcher.loftr_coarse.layers.4.v_proj    | Linear                  | 65.5 K\n",
      "118 | matcher.loftr_coarse.layers.4.attention | LinearAttention         | 0     \n",
      "119 | matcher.loftr_coarse.layers.4.merge     | Linear                  | 65.5 K\n",
      "120 | matcher.loftr_coarse.layers.4.mlp       | Sequential              | 393 K \n",
      "121 | matcher.loftr_coarse.layers.4.mlp.0     | Linear                  | 262 K \n",
      "122 | matcher.loftr_coarse.layers.4.mlp.1     | ReLU                    | 0     \n",
      "123 | matcher.loftr_coarse.layers.4.mlp.2     | Linear                  | 131 K \n",
      "124 | matcher.loftr_coarse.layers.4.norm1     | LayerNorm               | 512   \n",
      "125 | matcher.loftr_coarse.layers.4.norm2     | LayerNorm               | 512   \n",
      "126 | matcher.loftr_coarse.layers.5           | LoFTREncoderLayer       | 656 K \n",
      "127 | matcher.loftr_coarse.layers.5.q_proj    | Linear                  | 65.5 K\n",
      "128 | matcher.loftr_coarse.layers.5.k_proj    | Linear                  | 65.5 K\n",
      "129 | matcher.loftr_coarse.layers.5.v_proj    | Linear                  | 65.5 K\n",
      "130 | matcher.loftr_coarse.layers.5.attention | LinearAttention         | 0     \n",
      "131 | matcher.loftr_coarse.layers.5.merge     | Linear                  | 65.5 K\n",
      "132 | matcher.loftr_coarse.layers.5.mlp       | Sequential              | 393 K \n",
      "133 | matcher.loftr_coarse.layers.5.mlp.0     | Linear                  | 262 K \n",
      "134 | matcher.loftr_coarse.layers.5.mlp.1     | ReLU                    | 0     \n",
      "135 | matcher.loftr_coarse.layers.5.mlp.2     | Linear                  | 131 K \n",
      "136 | matcher.loftr_coarse.layers.5.norm1     | LayerNorm               | 512   \n",
      "137 | matcher.loftr_coarse.layers.5.norm2     | LayerNorm               | 512   \n",
      "138 | matcher.loftr_coarse.layers.6           | LoFTREncoderLayer       | 656 K \n",
      "139 | matcher.loftr_coarse.layers.6.q_proj    | Linear                  | 65.5 K\n",
      "140 | matcher.loftr_coarse.layers.6.k_proj    | Linear                  | 65.5 K\n",
      "141 | matcher.loftr_coarse.layers.6.v_proj    | Linear                  | 65.5 K\n",
      "142 | matcher.loftr_coarse.layers.6.attention | LinearAttention         | 0     \n",
      "143 | matcher.loftr_coarse.layers.6.merge     | Linear                  | 65.5 K\n",
      "144 | matcher.loftr_coarse.layers.6.mlp       | Sequential              | 393 K \n",
      "145 | matcher.loftr_coarse.layers.6.mlp.0     | Linear                  | 262 K \n",
      "146 | matcher.loftr_coarse.layers.6.mlp.1     | ReLU                    | 0     \n",
      "147 | matcher.loftr_coarse.layers.6.mlp.2     | Linear                  | 131 K \n",
      "148 | matcher.loftr_coarse.layers.6.norm1     | LayerNorm               | 512   \n",
      "149 | matcher.loftr_coarse.layers.6.norm2     | LayerNorm               | 512   \n",
      "150 | matcher.loftr_coarse.layers.7           | LoFTREncoderLayer       | 656 K \n",
      "151 | matcher.loftr_coarse.layers.7.q_proj    | Linear                  | 65.5 K\n",
      "152 | matcher.loftr_coarse.layers.7.k_proj    | Linear                  | 65.5 K\n",
      "153 | matcher.loftr_coarse.layers.7.v_proj    | Linear                  | 65.5 K\n",
      "154 | matcher.loftr_coarse.layers.7.attention | LinearAttention         | 0     \n",
      "155 | matcher.loftr_coarse.layers.7.merge     | Linear                  | 65.5 K\n",
      "156 | matcher.loftr_coarse.layers.7.mlp       | Sequential              | 393 K \n",
      "157 | matcher.loftr_coarse.layers.7.mlp.0     | Linear                  | 262 K \n",
      "158 | matcher.loftr_coarse.layers.7.mlp.1     | ReLU                    | 0     \n",
      "159 | matcher.loftr_coarse.layers.7.mlp.2     | Linear                  | 131 K \n",
      "160 | matcher.loftr_coarse.layers.7.norm1     | LayerNorm               | 512   \n",
      "161 | matcher.loftr_coarse.layers.7.norm2     | LayerNorm               | 512   \n",
      "162 | matcher.coarse_matching                 | CoarseMatching          | 0     \n",
      "163 | matcher.fine_preprocess                 | FinePreprocess          | 65.8 K\n",
      "164 | matcher.fine_preprocess.down_proj       | Linear                  | 32.9 K\n",
      "165 | matcher.fine_preprocess.merge_feat      | Linear                  | 32.9 K\n",
      "166 | matcher.loftr_fine                      | LocalFeatureTransformer | 328 K \n",
      "167 | matcher.loftr_fine.layers               | ModuleList              | 328 K \n",
      "168 | matcher.loftr_fine.layers.0             | LoFTREncoderLayer       | 164 K \n",
      "169 | matcher.loftr_fine.layers.0.q_proj      | Linear                  | 16.4 K\n",
      "170 | matcher.loftr_fine.layers.0.k_proj      | Linear                  | 16.4 K\n",
      "171 | matcher.loftr_fine.layers.0.v_proj      | Linear                  | 16.4 K\n",
      "172 | matcher.loftr_fine.layers.0.attention   | LinearAttention         | 0     \n",
      "173 | matcher.loftr_fine.layers.0.merge       | Linear                  | 16.4 K\n",
      "174 | matcher.loftr_fine.layers.0.mlp         | Sequential              | 98.3 K\n",
      "175 | matcher.loftr_fine.layers.0.mlp.0       | Linear                  | 65.5 K\n",
      "176 | matcher.loftr_fine.layers.0.mlp.1       | ReLU                    | 0     \n",
      "177 | matcher.loftr_fine.layers.0.mlp.2       | Linear                  | 32.8 K\n",
      "178 | matcher.loftr_fine.layers.0.norm1       | LayerNorm               | 256   \n",
      "179 | matcher.loftr_fine.layers.0.norm2       | LayerNorm               | 256   \n",
      "180 | matcher.loftr_fine.layers.1             | LoFTREncoderLayer       | 164 K \n",
      "181 | matcher.loftr_fine.layers.1.q_proj      | Linear                  | 16.4 K\n",
      "182 | matcher.loftr_fine.layers.1.k_proj      | Linear                  | 16.4 K\n",
      "183 | matcher.loftr_fine.layers.1.v_proj      | Linear                  | 16.4 K\n",
      "184 | matcher.loftr_fine.layers.1.attention   | LinearAttention         | 0     \n",
      "185 | matcher.loftr_fine.layers.1.merge       | Linear                  | 16.4 K\n",
      "186 | matcher.loftr_fine.layers.1.mlp         | Sequential              | 98.3 K\n",
      "187 | matcher.loftr_fine.layers.1.mlp.0       | Linear                  | 65.5 K\n",
      "188 | matcher.loftr_fine.layers.1.mlp.1       | ReLU                    | 0     \n",
      "189 | matcher.loftr_fine.layers.1.mlp.2       | Linear                  | 32.8 K\n",
      "190 | matcher.loftr_fine.layers.1.norm1       | LayerNorm               | 256   \n",
      "191 | matcher.loftr_fine.layers.1.norm2       | LayerNorm               | 256   \n",
      "192 | matcher.fine_matching                   | FineMatching            | 0     \n",
      "193 | loss                                    | LoFTRLoss               | 0     \n",
      "--------------------------------------------------------------------------------------\n",
      "11.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 M    Total params\n",
      "46.246    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "<torch.utils.data.dataset.ConcatDataset object at 0x7f6f3fdbf4c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "2022-06-02 11:25:33.014 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/85971045_11813536983.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/50643175_2354545518.jpg']]\n",
      "/root/image-matching-challenge-2022/./input/loftrutils/LoFTR-master/LoFTR-master/src/loftr/utils/coarse_matching.py:246: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  [i_ids % data['hw0_c'][1], i_ids // data['hw0_c'][1]],\n",
      "/root/image-matching-challenge-2022/./input/loftrutils/LoFTR-master/LoFTR-master/src/loftr/utils/coarse_matching.py:249: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  [j_ids % data['hw1_c'][1], j_ids // data['hw1_c'][1]],\n",
      "2022-06-02 11:25:36.226 | INFO     | src.utils.metrics:aggregate_metrics:182 - Aggregating metrics over 1 unique items...\n",
      "/usr/local/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d13db28ef94465f8b6b77cf67049f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 11:25:36.623 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/85971045_11813536983.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/50643175_2354545518.jpg']]\n",
      "2022-06-02 11:25:36.958 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:25:41.262 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/58267052_5109500221.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/12634021_4196123482.jpg']]\n",
      "2022-06-02 11:25:41.596 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:25:45.354 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/89367054_672839242.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/27795595_5462246797.jpg']]\n",
      "2022-06-02 11:25:45.697 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:25:47.389 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/94590912_8509601481.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/61430590_3750052872.jpg']]\n",
      "2022-06-02 11:25:47.736 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:25:49.424 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/66225128_7739308762.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/55194881_3897744248.jpg']]\n",
      "2022-06-02 11:25:49.768 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:25:51.473 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/85112064_8554016061.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/71608301_4258458200.jpg']]\n",
      "2022-06-02 11:25:51.818 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:25:53.526 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/91337580_5327631205.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/53931887_8392024402.jpg']]\n",
      "2022-06-02 11:25:53.873 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:25:58.054 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:25:59.796 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/62861187_5200568577.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/09071644_2938441433.jpg']]\n",
      "2022-06-02 11:26:00.141 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:04.051 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/85386984_3990647856.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/18348543_5140101294.jpg']]\n",
      "2022-06-02 11:26:04.396 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:06.131 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/50445672_2486344132.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/32833166_11938410.jpg']]\n",
      "2022-06-02 11:26:06.482 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:08.308 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/76104794_5487278337.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/26921609_5411058517.jpg']]\n",
      "2022-06-02 11:26:08.655 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:10.403 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/27753051_8325233672.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/07173372_2472510710.jpg']]\n",
      "2022-06-02 11:26:10.748 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:12.523 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/96241157_13980200233.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/10225532_6159971134.jpg']]\n",
      "2022-06-02 11:26:12.871 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:15.093 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:17.226 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:19.002 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/59170911_4886168484.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/35891445_339086379.jpg']]\n",
      "2022-06-02 11:26:19.351 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:21.499 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:27.828 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/91827308_8409403205.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/41942283_556283100.jpg']]\n",
      "2022-06-02 11:26:28.169 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:29.989 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/grand_place_brussels/images/75670494_10532227934.jpg'], ['./input/image-matching-challenge-2022/train/grand_place_brussels/images/06826935_2409168235.jpg']]\n",
      "2022-06-02 11:26:30.342 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:32.209 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/27175827_2221395482.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/05714706_2362913557.jpg']]\n",
      "2022-06-02 11:26:32.559 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:38.909 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/43500770_5422051381.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/08416575_2079441744.jpg']]\n",
      "2022-06-02 11:26:39.253 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:48.026 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/60726285_7846731866.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/14154970_13255420055.jpg']]\n",
      "2022-06-02 11:26:48.379 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:52.607 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/72565529_3540024224.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/71210930_8368609525.jpg']]\n",
      "2022-06-02 11:26:55.320 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:26:57.271 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/taj_mahal/images/42786563_4709824637.jpg'], ['./input/image-matching-challenge-2022/train/taj_mahal/images/12805395_8107250676.jpg']]\n",
      "2022-06-02 11:26:57.629 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:01.956 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/82700434_10482320586.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/78723734_3158991011.jpg']]\n",
      "2022-06-02 11:27:02.315 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:04.386 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/60056844_9552670556.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/54262713_729668662.jpg']]\n",
      "2022-06-02 11:27:04.742 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:07.158 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:13.978 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/91459499_704552898.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/21652730_3109986955.jpg']]\n",
      "2022-06-02 11:27:14.335 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:21.638 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:24.084 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:28.736 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/78017032_5434649890.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/17657592_4442000848.jpg']]\n",
      "2022-06-02 11:27:29.094 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:31.180 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/76896497_7157877064.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/73818831_436973859.jpg']]\n",
      "2022-06-02 11:27:31.544 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:33.663 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/38213650_3618323068.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/31273791_2085849876.jpg']]\n",
      "2022-06-02 11:27:34.024 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:46.688 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:51.425 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/95625413_8728828714.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/68517155_168393151.jpg']]\n",
      "2022-06-02 11:27:51.791 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:53.985 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/89964911_8604178342.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/37387513_13902484871.jpg']]\n",
      "2022-06-02 11:27:54.344 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:27:59.168 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/85397053_1435622623.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/38596937_3472978265.jpg']]\n",
      "2022-06-02 11:27:59.535 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:06.992 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/70811159_74069766.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/57994158_6285704604.jpg']]\n",
      "2022-06-02 11:28:07.358 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:09.588 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/92515397_448839884.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/68746686_8152199425.jpg']]\n",
      "2022-06-02 11:28:09.950 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:17.450 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/77475468_4135175833.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/06863689_7353555136.jpg']]\n",
      "2022-06-02 11:28:17.818 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:28.057 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/51846360_3107416213.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/49659818_12133076156.jpg']]\n",
      "2022-06-02 11:28:28.416 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:31.092 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:33.765 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:36.073 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/57385155_2810071.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/17547492_3217278798.jpg']]\n",
      "2022-06-02 11:28:36.426 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:46.731 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/47925804_248181354.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/04177294_2158525863.jpg']]\n",
      "2022-06-02 11:28:47.083 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:49.792 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:28:52.157 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/97299190_230228215.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/04879345_5872446713.jpg']]\n",
      "2022-06-02 11:28:52.503 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:11.442 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:14.187 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:16.584 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/68758584_335393201.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/38780637_1435758036.jpg']]\n",
      "2022-06-02 11:29:16.932 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:19.347 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/95119654_3421015490.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/75852356_8914806709.jpg']]\n",
      "2022-06-02 11:29:19.696 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:22.504 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:30.612 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/95123034_5124175928.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/48382453_4614813705.jpg']]\n",
      "2022-06-02 11:29:30.957 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:33.445 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/lincoln_memorial_statue/images/93409848_5535963552.jpg'], ['./input/image-matching-challenge-2022/train/lincoln_memorial_statue/images/65101356_2668964566.jpg']]\n",
      "2022-06-02 11:29:33.791 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:36.224 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/69822954_13937126696.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/68758584_335393201.jpg']]\n",
      "2022-06-02 11:29:36.569 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:39.043 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/lincoln_memorial_statue/images/96041539_3414552661.jpg'], ['./input/image-matching-challenge-2022/train/lincoln_memorial_statue/images/54936077_10385154344.jpg']]\n",
      "2022-06-02 11:29:39.385 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:42.197 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:50.717 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:53.553 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:29:56.082 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/55576845_8996024959.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/22323200_4314028949.jpg']]\n",
      "2022-06-02 11:29:56.424 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:07.920 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:13.363 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/10560264_12522833544.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/04364411_6931256047.jpg']]\n",
      "2022-06-02 11:30:13.706 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:16.229 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/90873732_2346257740.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/18865921_5109712344.jpg']]\n",
      "2022-06-02 11:30:16.575 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:19.181 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/18933011_9395787270.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/07361860_4676095706.jpg']]\n",
      "2022-06-02 11:30:19.526 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:22.474 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:25.227 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/70690360_2494937213.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/25645130_3339958318.jpg']]\n",
      "2022-06-02 11:30:25.572 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:28.208 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/temple_nara_japan/images/95264086_6694083417.jpg'], ['./input/image-matching-challenge-2022/train/temple_nara_japan/images/59757978_7385293140.jpg']]\n",
      "2022-06-02 11:30:28.550 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:31.496 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:34.119 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/95968276_430652270.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/32426067_492457964.jpg']]\n",
      "2022-06-02 11:30:34.457 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:37.071 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/50445672_2486344132.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/27082669_4150807504.jpg']]\n",
      "2022-06-02 11:30:37.417 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:40.426 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:43.075 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/79809971_308557128.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/12823568_9611405424.jpg']]\n",
      "2022-06-02 11:30:43.417 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:49.418 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:52.090 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/44212641_508652910.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/29753896_185333290.jpg']]\n",
      "2022-06-02 11:30:52.436 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:55.449 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:30:58.136 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/88240236_5734632269.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/16403666_4619513285.jpg']]\n",
      "2022-06-02 11:30:58.483 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:04.258 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/86907112_19784933.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/00477537_2308691804.jpg']]\n",
      "2022-06-02 11:31:04.603 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:07.368 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/95833187_2231595711.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/23195958_3383514084.jpg']]\n",
      "2022-06-02 11:31:07.713 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:10.812 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:13.583 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/51162905_8007351784.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/14195208_276265172.jpg']]\n",
      "2022-06-02 11:31:13.930 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:16.689 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/84357746_4061156508.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/52006272_87375522.jpg']]\n",
      "2022-06-02 11:31:17.034 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:29.587 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:35.887 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:41.892 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/29754296_3786913684.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/07566136_2407249333.jpg']]\n",
      "2022-06-02 11:31:42.240 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:48.545 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:51.396 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/40314568_156178830.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/16566576_414901882.jpg']]\n",
      "2022-06-02 11:31:51.744 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:31:58.276 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:11.189 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/59018964_13568445963.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/57090695_8548496597.jpg']]\n",
      "2022-06-02 11:32:11.533 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:14.745 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:17.726 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/99804374_8024711160.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/34238646_4422693538.jpg']]\n",
      "2022-06-02 11:32:18.071 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:21.003 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/78878255_3496324551.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/54035419_2644847805.jpg']]\n",
      "2022-06-02 11:32:21.352 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:37.920 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/taj_mahal/images/90695333_6615489555.jpg'], ['./input/image-matching-challenge-2022/train/taj_mahal/images/18222110_1341172152.jpg']]\n",
      "2022-06-02 11:32:38.270 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:41.248 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/86370842_5935029406.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/84616443_5110095780.jpg']]\n",
      "2022-06-02 11:32:41.591 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:50.064 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:54.032 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/temple_nara_japan/images/45579743_8655442784.jpg'], ['./input/image-matching-challenge-2022/train/temple_nara_japan/images/43498552_8530806471.jpg']]\n",
      "2022-06-02 11:32:54.394 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:32:58.754 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:03.143 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:15.908 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/84639561_2696027842.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/68164742_4661248806.jpg']]\n",
      "2022-06-02 11:33:16.308 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:20.238 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/97459387_6063434419.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/71415904_5186382281.jpg']]\n",
      "2022-06-02 11:33:20.593 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:24.470 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/73697494_3197549686.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/37387513_13902484871.jpg']]\n",
      "2022-06-02 11:33:24.819 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:28.744 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/70089144_2698758857.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/42353168_2432785869.jpg']]\n",
      "2022-06-02 11:33:29.131 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:33.083 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/76821098_729659754.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/12180652_2423430199.jpg']]\n",
      "2022-06-02 11:33:33.459 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:41.510 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:55.434 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/40580817_2599681870.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/04861657_8587228495.jpg']]\n",
      "2022-06-02 11:33:55.790 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:33:58.987 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/70811159_74069766.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/69700527_2765210743.jpg']]\n",
      "2022-06-02 11:33:59.347 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:02.963 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:06.210 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/37055004_225870212.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/11134066_2199195810.jpg']]\n",
      "2022-06-02 11:34:06.568 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:09.792 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/91136231_4677075766.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/64523389_2561024232.jpg']]\n",
      "2022-06-02 11:34:10.142 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:13.689 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:16.959 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/52431988_1267401313.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/45698441_158759054.jpg']]\n",
      "2022-06-02 11:34:17.321 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:20.949 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:24.205 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/96747100_6960036479.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/02189109_4611484390.jpg']]\n",
      "2022-06-02 11:34:24.561 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:31.854 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:46.312 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/39658358_2981688579.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/03890690_2728701915.jpg']]\n",
      "2022-06-02 11:34:46.670 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:49.988 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/81348364_121926770.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/23270542_4210156925.jpg']]\n",
      "2022-06-02 11:34:50.350 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:54.042 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:34:57.401 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/75553445_4718379758.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/68138970_5115061130.jpg']]\n",
      "2022-06-02 11:34:57.764 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:01.164 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/92454639_4933798929.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/54693720_1410642963.jpg']]\n",
      "2022-06-02 11:35:01.526 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:04.871 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/87574592_5148231049.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/17647055_4030815991.jpg']]\n",
      "2022-06-02 11:35:05.232 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:08.962 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:16.152 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/15398269_3559004259.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/15039961_9488363010.jpg']]\n",
      "2022-06-02 11:35:16.502 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:20.172 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:23.963 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:27.394 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/93373376_5987184804.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/05856832_512395523.jpg']]\n",
      "2022-06-02 11:35:27.757 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:31.189 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/64728097_4242652776.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/56383511_4575849881.jpg']]\n",
      "2022-06-02 11:35:31.548 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:38.842 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/28625612_4768475219.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/23555145_4863441569.jpg']]\n",
      "2022-06-02 11:35:39.204 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:43.042 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:50.704 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:35:57.999 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/96715379_478755434.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/95357069_10894925523.jpg']]\n",
      "2022-06-02 11:35:58.355 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:06.153 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:10.009 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:17.882 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:21.385 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/81409989_5495330211.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/52006272_87375522.jpg']]\n",
      "2022-06-02 11:36:21.736 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:25.289 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/65900065_5072163174.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/17586341_3971392474.jpg']]\n",
      "2022-06-02 11:36:25.651 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:33.498 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:40.996 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/86800622_2461469660.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/60209493_4922523243.jpg']]\n",
      "2022-06-02 11:36:41.355 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:44.964 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/74108067_2210997487.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/03411205_108198818.jpg']]\n",
      "2022-06-02 11:36:45.306 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:53.212 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:36:57.174 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:37:00.797 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/49624348_9321304154.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/02530866_2716822090.jpg']]\n",
      "2022-06-02 11:37:01.165 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:37:21.114 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:37:33.220 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:37:36.947 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/piazza_san_marco/images/60642120_4838112159.jpg'], ['./input/image-matching-challenge-2022/train/piazza_san_marco/images/19489590_236391387.jpg']]\n",
      "2022-06-02 11:37:37.318 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:37:49.141 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/73823709_2379577727.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/60707869_945821902.jpg']]\n",
      "2022-06-02 11:37:49.514 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:37:53.240 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/69856507_2078653541.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/07173372_2472510710.jpg']]\n",
      "2022-06-02 11:37:53.597 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:37:57.748 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:38:10.222 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:38:14.453 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:38:18.263 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/68530644_3241934392.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/66242136_8466472338.jpg']]\n",
      "2022-06-02 11:38:18.653 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:38:22.822 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:38:30.836 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/33729878_8818031078.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/32462671_5775606898.jpg']]\n",
      "2022-06-02 11:38:31.193 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:38:35.115 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/84693101_5071593401.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/66405145_5846589580.jpg']]\n",
      "2022-06-02 11:38:35.466 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:38:43.484 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/98283507_7198318944.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/64525140_4621146558.jpg']]\n",
      "2022-06-02 11:38:43.862 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:38:51.899 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/27753051_8325233672.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/03758560_3339132723.jpg']]\n",
      "2022-06-02 11:38:52.294 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:39:17.818 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/80904217_8471724844.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/77475468_4135175833.jpg']]\n",
      "2022-06-02 11:39:18.179 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:39:22.067 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/61063899_400274669.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/19022186_2285670951.jpg']]\n",
      "2022-06-02 11:39:22.459 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:39:26.406 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/69614189_6214967945.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/31366933_512780127.jpg']]\n",
      "2022-06-02 11:39:26.775 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:39:30.719 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/89918126_5084271.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/72551743_4993190869.jpg']]\n",
      "2022-06-02 11:39:31.100 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:39:35.063 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/87213063_4987975330.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/76142754_4630938291.jpg']]\n",
      "2022-06-02 11:39:35.427 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:39:39.413 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/94258679_133127861.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/68844183_703665665.jpg']]\n",
      "2022-06-02 11:39:39.814 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:39:43.800 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/59331375_2244201695.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/09935454_8681061641.jpg']]\n",
      "2022-06-02 11:39:44.173 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:39:52.557 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/89158855_4693380521.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/34684674_2338795314.jpg']]\n",
      "2022-06-02 11:39:52.934 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:01.734 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:06.122 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:10.163 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/sacre_coeur/images/59269571_2206364373.jpg'], ['./input/image-matching-challenge-2022/train/sacre_coeur/images/51947152_4145834562.jpg']]\n",
      "2022-06-02 11:40:10.530 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:14.544 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/38036094_2116526267.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/01763245_4725563330.jpg']]\n",
      "2022-06-02 11:40:14.906 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:18.956 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/97213998_4583655992.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/16244187_8465557021.jpg']]\n",
      "2022-06-02 11:40:19.323 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:23.431 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/grand_place_brussels/images/76033783_4998492930.jpg'], ['./input/image-matching-challenge-2022/train/grand_place_brussels/images/74949128_744301420.jpg']]\n",
      "2022-06-02 11:40:23.788 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:32.298 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/73517833_3531806548.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/71859903_5840833015.jpg']]\n",
      "2022-06-02 11:40:32.656 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:41.289 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/77475468_4135175833.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/53208747_4264002612.jpg']]\n",
      "2022-06-02 11:40:41.661 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:45.709 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/87967199_8224990487.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/26154419_4293412724.jpg']]\n",
      "2022-06-02 11:40:46.090 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:50.552 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:54.635 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/49890372_4036180560.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/43679560_2207962924.jpg']]\n",
      "2022-06-02 11:40:54.992 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:40:59.474 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:41:03.611 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/96546150_4831698194.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/55213213_5402502744.jpg']]\n",
      "2022-06-02 11:41:03.999 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:41:17.573 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:41:21.716 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/29281983_5767482367.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/02785321_3713830095.jpg']]\n",
      "2022-06-02 11:41:22.113 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:41:26.265 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/72946763_430640996.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/70326181_5251675186.jpg']]\n",
      "2022-06-02 11:41:26.633 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:41:30.791 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/76359394_5579433310.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/07739469_9102054751.jpg']]\n",
      "2022-06-02 11:41:31.177 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:41:39.890 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/91262088_2232387728.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/28720243_4419858244.jpg']]\n",
      "2022-06-02 11:41:40.263 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:41:49.124 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/27997386_12350137553.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/21697383_6430594307.jpg']]\n",
      "2022-06-02 11:41:49.509 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:41:53.728 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/64369288_3596464942.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/52299415_5766130728.jpg']]\n",
      "2022-06-02 11:41:54.124 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:42:12.307 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/82540674_11599286604.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/79809971_308557128.jpg']]\n",
      "2022-06-02 11:42:12.684 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:42:16.986 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/95865994_275402759.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/54381758_9693152009.jpg']]\n",
      "2022-06-02 11:42:17.348 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:42:21.580 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/65544439_10894696656.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/19022186_2285670951.jpg']]\n",
      "2022-06-02 11:42:21.949 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:42:26.236 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/65917848_5578849347.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/35467033_3245815278.jpg']]\n",
      "2022-06-02 11:42:26.599 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:42:35.781 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/63362920_8594646157.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/02989085_1413183882.jpg']]\n",
      "2022-06-02 11:42:36.189 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:42:45.236 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/13620440_3894790818.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/10935609_8427414076.jpg']]\n",
      "2022-06-02 11:42:45.641 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:42:54.684 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/77282490_453023076.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/17210850_4528374353.jpg']]\n",
      "2022-06-02 11:42:55.096 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:04.181 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/58658028_480552247.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/55194881_3897744248.jpg']]\n",
      "2022-06-02 11:43:04.594 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:09.446 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:13.834 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/82976279_6426687509.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/60723133_7091929211.jpg']]\n",
      "2022-06-02 11:43:14.251 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:19.102 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:23.954 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:28.423 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/56493755_3454995877.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/15457887_10227170235.jpg']]\n",
      "2022-06-02 11:43:28.793 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:38.043 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/17378230_8657377873.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/14889160_4342863394.jpg']]\n",
      "2022-06-02 11:43:38.436 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:48.223 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:43:52.681 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/48681712_7005791569.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/28625612_4768475219.jpg']]\n",
      "2022-06-02 11:43:53.094 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:02.517 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/98855661_2057774892.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/63569452_4011904833.jpg']]\n",
      "2022-06-02 11:44:02.905 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:07.813 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:12.302 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/79266619_6540071407.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/39410329_2726398747.jpg']]\n",
      "2022-06-02 11:44:12.684 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:17.219 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/82232765_255221151.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/18593928_7766559772.jpg']]\n",
      "2022-06-02 11:44:17.611 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:22.124 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/sacre_coeur/images/66392089_2579475865.jpg'], ['./input/image-matching-challenge-2022/train/sacre_coeur/images/61457833_5673912363.jpg']]\n",
      "2022-06-02 11:44:22.523 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:27.029 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/74905940_10894469605.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/54869923_2442824829.jpg']]\n",
      "2022-06-02 11:44:27.399 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:31.949 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/82724591_6779971696.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/32934563_2735018403.jpg']]\n",
      "2022-06-02 11:44:32.364 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:41.891 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/36373371_5957405170.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/23065795_12789861543.jpg']]\n",
      "2022-06-02 11:44:42.278 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:46.845 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/58722268_3973887300.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/10117854_6006891510.jpg']]\n",
      "2022-06-02 11:44:47.257 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:51.811 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/53608526_492795924.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/11547542_6014864584.jpg']]\n",
      "2022-06-02 11:44:52.187 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:44:56.815 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/95691091_4993817560.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/15795937_5270181220.jpg']]\n",
      "2022-06-02 11:44:57.187 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:45:16.922 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/76924854_5406455624.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/63324241_2336485307.jpg']]\n",
      "2022-06-02 11:45:17.310 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:45:22.025 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/67187460_10016317323.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/54148692_127406449.jpg']]\n",
      "2022-06-02 11:45:22.410 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:45:32.216 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/36155741_4419737478.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/28624903_4696158328.jpg']]\n",
      "2022-06-02 11:45:32.606 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:45:37.646 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:45:42.313 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/grand_place_brussels/images/83880039_8704930508.jpg'], ['./input/image-matching-challenge-2022/train/grand_place_brussels/images/63023054_7575192460.jpg']]\n",
      "2022-06-02 11:45:42.683 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:45:47.362 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/grand_place_brussels/images/63831138_11531850475.jpg'], ['./input/image-matching-challenge-2022/train/grand_place_brussels/images/32234104_183977071.jpg']]\n",
      "2022-06-02 11:45:47.734 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:45:52.398 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/taj_mahal/images/94748108_2123852059.jpg'], ['./input/image-matching-challenge-2022/train/taj_mahal/images/27545100_3298431981.jpg']]\n",
      "2022-06-02 11:45:52.769 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:45:57.825 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:46:02.945 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:46:07.602 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/30098134_3447966505.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/10117854_6006891510.jpg']]\n",
      "2022-06-02 11:46:08.009 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:46:17.796 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/sacre_coeur/images/76611857_9600863579.jpg'], ['./input/image-matching-challenge-2022/train/sacre_coeur/images/08081221_11367454663.jpg']]\n",
      "2022-06-02 11:46:18.186 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:46:22.910 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/british_museum/images/65206173_3746925945.jpg'], ['./input/image-matching-challenge-2022/train/british_museum/images/09740642_11372944273.jpg']]\n",
      "2022-06-02 11:46:23.312 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:46:28.015 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/53897060_559403450.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/37387513_13902484871.jpg']]\n",
      "2022-06-02 11:46:28.395 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:46:48.629 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/98446525_8467892061.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/83719143_5979169560.jpg']]\n",
      "2022-06-02 11:46:49.033 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:46:54.888 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/94258679_133127861.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/46652113_4920632311.jpg']]\n",
      "2022-06-02 11:46:55.303 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:47:01.954 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:47:08.634 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:47:28.369 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/72331083_4151327128.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/56946632_10536573515.jpg']]\n",
      "2022-06-02 11:47:28.748 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:47:48.363 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/22254583_3751963741.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/16395195_8914814311.jpg']]\n",
      "2022-06-02 11:47:48.751 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:48:15.564 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/taj_mahal/images/99197644_6429113061.jpg'], ['./input/image-matching-challenge-2022/train/taj_mahal/images/88858192_1500546390.jpg']]\n",
      "2022-06-02 11:48:15.979 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:48:22.389 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/81007852_203832770.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/51522762_2340393097.jpg']]\n",
      "2022-06-02 11:48:22.797 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:48:29.155 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/98116398_6308559610.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/49538526_9562599702.jpg']]\n",
      "2022-06-02 11:48:29.523 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:48:42.608 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/43335638_88784147.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/34297396_3396470129.jpg']]\n",
      "2022-06-02 11:48:42.993 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:49:03.371 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:49:09.824 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/91262088_2232387728.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/68592554_3723959857.jpg']]\n",
      "2022-06-02 11:49:10.196 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:49:16.652 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/66764693_6618921233.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/19022186_2285670951.jpg']]\n",
      "2022-06-02 11:49:17.037 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:49:30.503 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/14354374_248601406.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/01693398_89866367.jpg']]\n",
      "2022-06-02 11:49:30.885 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:49:37.308 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/70576580_5200696647.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/51522762_2340393097.jpg']]\n",
      "2022-06-02 11:49:37.698 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:49:44.113 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/78569408_2977266475.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/60694437_400272673.jpg']]\n",
      "2022-06-02 11:49:44.525 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:49:57.894 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/sacre_coeur/images/75716321_3698743515.jpg'], ['./input/image-matching-challenge-2022/train/sacre_coeur/images/45575968_5097432755.jpg']]\n",
      "2022-06-02 11:49:58.265 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:50:11.609 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/60114560_3048539062.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/28685407_2933550018.jpg']]\n",
      "2022-06-02 11:50:12.007 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:50:25.534 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/62374345_335403436.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/01872634_173583139.jpg']]\n",
      "2022-06-02 11:50:25.950 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:50:32.458 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/53877981_634301318.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/41320922_8862697787.jpg']]\n",
      "2022-06-02 11:50:32.843 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:50:39.365 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/94077688_2361241390.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/35076671_12139869076.jpg']]\n",
      "2022-06-02 11:50:39.759 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:50:46.232 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/81545978_104769022.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/47607597_744116397.jpg']]\n",
      "2022-06-02 11:50:46.655 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:50:53.567 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:51:07.436 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:51:21.135 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/lincoln_memorial_statue/images/46644731_4772610948.jpg'], ['./input/image-matching-challenge-2022/train/lincoln_memorial_statue/images/28255428_2899793835.jpg']]\n",
      "2022-06-02 11:51:21.514 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:51:28.144 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/84736699_13960528815.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/67484798_514709769.jpg']]\n",
      "2022-06-02 11:51:28.535 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:51:49.461 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:51:56.102 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/95285734_5746652536.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/80049667_3641938865.jpg']]\n",
      "2022-06-02 11:51:56.498 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:52:03.125 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/90107250_10894943213.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/73631590_5090303693.jpg']]\n",
      "2022-06-02 11:52:03.523 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:52:10.157 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/89443453_2756566096.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/40981306_1504810601.jpg']]\n",
      "2022-06-02 11:52:10.566 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:52:17.692 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:52:24.445 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/24314265_4777673294.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/17273683_8481877430.jpg']]\n",
      "2022-06-02 11:52:24.853 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:52:31.974 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:52:38.656 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/87227869_4500051201.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/84140545_5204369717.jpg']]\n",
      "2022-06-02 11:52:39.049 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:52:52.843 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/55708664_8250830435.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/04785646_8607050988.jpg']]\n",
      "2022-06-02 11:52:53.217 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:52:59.900 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/94887785_2665835098.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/34310131_1423257207.jpg']]\n",
      "2022-06-02 11:53:00.265 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:53:06.943 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/92715744_6780027938.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/00134044_3433575797.jpg']]\n",
      "2022-06-02 11:53:07.299 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:53:13.930 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/taj_mahal/images/88950491_3028703363.jpg'], ['./input/image-matching-challenge-2022/train/taj_mahal/images/59361103_6117380533.jpg']]\n",
      "2022-06-02 11:53:14.305 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:53:20.944 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/34684674_2338795314.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/17750259_5579050866.jpg']]\n",
      "2022-06-02 11:53:21.338 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:53:28.409 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:53:35.073 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/72692578_3340340819.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/55876279_430770041.jpg']]\n",
      "2022-06-02 11:53:35.441 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:53:49.173 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/96647518_7739315718.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/42339817_2799366536.jpg']]\n",
      "2022-06-02 11:53:49.528 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:53:56.216 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/67730594_3178277716.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/18775801_524665082.jpg']]\n",
      "2022-06-02 11:53:56.569 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:54:03.214 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/63942109_7550612726.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/45047580_3986250227.jpg']]\n",
      "2022-06-02 11:54:03.590 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:54:10.258 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/95345147_2076154657.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/82700434_10482320586.jpg']]\n",
      "2022-06-02 11:54:10.633 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:54:31.932 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/85214795_275603952.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/00977754_11239843025.jpg']]\n",
      "2022-06-02 11:54:32.321 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:54:39.269 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/30720370_7714994982.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/24536118_236584259.jpg']]\n",
      "2022-06-02 11:54:39.616 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:54:46.758 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:54:53.539 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/62082070_6184007632.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/40002377_3778050114.jpg']]\n",
      "2022-06-02 11:54:53.889 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:55:00.675 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/62014844_2665832756.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/60713194_2656171721.jpg']]\n",
      "2022-06-02 11:55:01.064 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:55:15.384 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:55:22.235 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/37331853_10765592124.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/26328381_8915440198.jpg']]\n",
      "2022-06-02 11:55:22.615 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:55:29.481 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/84056637_8972124892.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/08416575_2079441744.jpg']]\n",
      "2022-06-02 11:55:29.854 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:55:37.064 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:55:51.549 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:55:58.373 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/british_museum/images/39461890_106560712.jpg'], ['./input/image-matching-challenge-2022/train/british_museum/images/29840064_6240820088.jpg']]\n",
      "2022-06-02 11:55:58.774 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:56:12.907 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/60241607_5787353916.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/34310131_1423257207.jpg']]\n",
      "2022-06-02 11:56:13.283 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:56:20.550 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:56:35.227 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:56:42.503 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:57:04.019 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/74554695_3147702645.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/23167381_2973226361.jpg']]\n",
      "2022-06-02 11:57:04.382 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:57:25.866 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/41200923_4257148931.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/03746789_4463922325.jpg']]\n",
      "2022-06-02 11:57:26.260 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:57:33.240 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/78842056_325218062.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/58732203_2711105477.jpg']]\n",
      "2022-06-02 11:57:33.616 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:57:40.604 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/65296387_3868444118.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/58759884_4635709645.jpg']]\n",
      "2022-06-02 11:57:40.971 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:57:47.860 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/72565529_3540024224.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/70327098_5598546423.jpg']]\n",
      "2022-06-02 11:57:55.191 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/british_museum/images/90095149_11613863483.jpg'], ['./input/image-matching-challenge-2022/train/british_museum/images/85606696_422460321.jpg']]\n",
      "2022-06-02 11:57:55.584 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:58:10.406 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:58:17.781 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:58:24.835 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/80033497_4005059735.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/61595172_7024779117.jpg']]\n",
      "2022-06-02 11:58:25.211 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:58:32.635 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:58:47.156 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/69191358_2983396830.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/32062315_146512503.jpg']]\n",
      "2022-06-02 11:58:47.544 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:58:54.604 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/53271175_196359090.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/33682928_6003264911.jpg']]\n",
      "2022-06-02 11:58:54.979 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:59:01.979 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/98127275_6325581764.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/77306992_480542662.jpg']]\n",
      "2022-06-02 11:59:02.384 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:59:24.770 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:59:31.903 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/33964121_8571233470.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/21199057_9310270417.jpg']]\n",
      "2022-06-02 11:59:32.278 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:59:39.450 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/76278732_3503423992.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/71885906_177077232.jpg']]\n",
      "2022-06-02 11:59:39.838 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 11:59:46.917 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/80288369_2336500045.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/25347672_8986849588.jpg']]\n",
      "2022-06-02 11:59:47.290 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:00:09.355 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/44970818_8152290713.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/42602384_5562334802.jpg']]\n",
      "2022-06-02 12:00:09.755 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:00:17.223 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:00:24.770 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:00:39.543 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/18990907_13666504113.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/10402018_2337155230.jpg']]\n",
      "2022-06-02 12:00:39.942 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:00:47.112 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/80033497_4005059735.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/11817780_433570693.jpg']]\n",
      "2022-06-02 12:00:47.483 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:00:54.634 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/74782834_3699068147.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/73389236_9646667567.jpg']]\n",
      "2022-06-02 12:00:55.037 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:01:02.245 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/taj_mahal/images/51122773_11163691045.jpg'], ['./input/image-matching-challenge-2022/train/taj_mahal/images/18431346_3891005633.jpg']]\n",
      "2022-06-02 12:01:02.652 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:01:17.883 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:01:33.113 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:01:40.381 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/36110882_5047650746.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/23381049_4621713332.jpg']]\n",
      "2022-06-02 12:01:40.752 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:02:18.542 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/30725650_6031692319.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/00644051_242819650.jpg']]\n",
      "2022-06-02 12:02:18.925 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:02:33.977 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/grand_place_brussels/images/91887585_2717484563.jpg'], ['./input/image-matching-challenge-2022/train/grand_place_brussels/images/10479978_4543725197.jpg']]\n",
      "2022-06-02 12:02:34.373 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:02:49.571 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/93332159_4660811054.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/41465586_2085807482.jpg']]\n",
      "2022-06-02 12:02:49.944 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:03:05.126 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/94184116_2791946095.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/86519836_7750565822.jpg']]\n",
      "2022-06-02 12:03:05.540 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:03:12.987 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/96106107_13957342172.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/05214414_4769113658.jpg']]\n",
      "2022-06-02 12:03:13.389 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:03:29.063 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:03:36.916 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:03:44.364 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/60853708_3271891046.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/55173965_4252121546.jpg']]\n",
      "2022-06-02 12:03:44.769 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:03:52.535 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:03:59.978 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/60110645_228039409.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/16578102_7453737144.jpg']]\n",
      "2022-06-02 12:04:00.374 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:04:15.696 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/pantheon_exterior/images/59557427_374463551.jpg'], ['./input/image-matching-challenge-2022/train/pantheon_exterior/images/25499433_191591241.jpg']]\n",
      "2022-06-02 12:04:16.107 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:04:23.853 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:04:31.316 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/63157163_4725501764.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/52144216_2711106071.jpg']]\n",
      "2022-06-02 12:04:31.696 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 12:04:39.193 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/85971045_11813536983.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/50643175_2354545518.jpg']]\n",
      "2022-06-02 12:04:41.512 | INFO     | src.utils.metrics:aggregate_metrics:182 - Aggregating metrics over 1 unique items...\n",
      "Epoch 0, global step 500: 'auc@10' reached 0.00000 (best 0.00000), saving model to '/root/image-matching-challenge-2022/logs/tb_logs/final_training/version_3/checkpoints/epoch=0-auc@5=0.000-auc@10=0.000-auc@20=0.000.ckpt' as top 5\n",
      "2022-06-02 12:04:51.743 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/85971045_11813536983.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/50643175_2354545518.jpg']]\n",
      "2022-06-02 12:04:52.194 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:04:58.598 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/58267052_5109500221.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/12634021_4196123482.jpg']]\n",
      "2022-06-02 12:04:58.968 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:05:12.166 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/buckingham_palace/images/89367054_672839242.jpg'], ['./input/image-matching-challenge-2022/train/buckingham_palace/images/27795595_5462246797.jpg']]\n",
      "2022-06-02 12:05:12.570 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:05:18.965 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/94590912_8509601481.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/61430590_3750052872.jpg']]\n",
      "2022-06-02 12:05:19.347 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:05:25.766 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/66225128_7739308762.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/55194881_3897744248.jpg']]\n",
      "2022-06-02 12:05:26.134 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:05:33.003 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/st_peters_square/images/85112064_8554016061.jpg'], ['./input/image-matching-challenge-2022/train/st_peters_square/images/71608301_4258458200.jpg']]\n",
      "2022-06-02 12:05:33.373 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:05:39.776 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/colosseum_exterior/images/91337580_5327631205.jpg'], ['./input/image-matching-challenge-2022/train/colosseum_exterior/images/53931887_8392024402.jpg']]\n",
      "2022-06-02 12:05:40.179 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:05:53.868 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:06:00.301 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/62861187_5200568577.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/09071644_2938441433.jpg']]\n",
      "2022-06-02 12:06:00.695 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:06:13.996 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/brandenburg_gate/images/85386984_3990647856.jpg'], ['./input/image-matching-challenge-2022/train/brandenburg_gate/images/18348543_5140101294.jpg']]\n",
      "2022-06-02 12:06:14.384 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:06:20.821 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/50445672_2486344132.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/32833166_11938410.jpg']]\n",
      "2022-06-02 12:06:21.217 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:06:27.728 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/trevi_fountain/images/76104794_5487278337.jpg'], ['./input/image-matching-challenge-2022/train/trevi_fountain/images/26921609_5411058517.jpg']]\n",
      "2022-06-02 12:06:28.095 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:06:34.565 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/27753051_8325233672.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/07173372_2472510710.jpg']]\n",
      "2022-06-02 12:06:34.933 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:06:41.410 | WARNING  | src.loftr.utils.supervision:spvs_coarse:93 - No groundtruth coarse match found for: [['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/96241157_13980200233.jpg'], ['./input/image-matching-challenge-2022/train/notre_dame_front_facade/images/10225532_6159971134.jpg']]\n",
      "2022-06-02 12:06:41.779 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "2022-06-02 12:06:48.763 | WARNING  | src.losses.loftr_loss:_compute_fine_loss_l2_std:140 - assign a false supervision to avoid ddp deadlock\n",
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/image-matching-challenge-2022/logs/tb_logs/final_training/version_0/checkpoints\n"
     ]
    }
   ],
   "source": [
    "if SAGEMAKER_IMAGE:\n",
    "    %cd ./logs/tb_logs/final_training/version_0/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=0-auc@5=0.000-auc@10=0.000-auc@20=0.000.ckpt'\n",
      "'epoch=1-auc@5=0.000-auc@10=0.000-auc@20=0.000.ckpt'\n",
      "'epoch=2-auc@5=0.000-auc@10=0.000-auc@20=0.000.ckpt'\n",
      " last.ckpt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-base-python-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
